{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Lightweight ASGI Web Framework \u00b6 This is a web framework for ASGI servers in Python 3.7. The goal is to provide a minimal implementation, with other facilities (serving static files, CORS, sessions, etc.) being implemented by optional packages in an attempt to keep the implementation clear and lightweight.","title":"Lightweight ASGI Web Framework"},{"location":"#lightweight-asgi-web-framework","text":"This is a web framework for ASGI servers in Python 3.7. The goal is to provide a minimal implementation, with other facilities (serving static files, CORS, sessions, etc.) being implemented by optional packages in an attempt to keep the implementation clear and lightweight.","title":"Lightweight ASGI Web Framework"},{"location":"api/bareasgi.basic_router/","text":"module bareasgi.basic_router.http_router \u00b6 Summary \u00b6 Http Routing class BasicHttpRouter ( HttpRouter ) \u00b6 Summary \u00b6 A basic http routing implementation bareasgi.basic_router . BasicHttpRouter ( not_found_response : Union[intTuple[intUnionListTuple[bytes, bytes]], NoneTypeTuple[intUnionListTuple[bytes, bytes]], NoneTypeUnionAsyncIterable[bytes], NoneTypeTuple[intUnionListTuple[bytes, bytes]], NoneTypeUnionAsyncIterable[bytes], NoneTypeUnionIterableTuple[strListTuple[bytes, bytes]]]], NoneType]]] ) -> None Parameters \u00b6 not_found_response : Union[intTuple[intUnionListTuple[bytes, bytes]], NoneTypeTuple[intUnionListTuple[bytes, bytes]], NoneTypeUnionAsyncIterable[bytes], NoneTypeTuple[intUnionListTuple[bytes, bytes]], NoneTypeUnionAsyncIterable[bytes], NoneTypeUnionIterableTuple[strListTuple[bytes, bytes]]]], NoneType]]] property BasicHttpRouter . not_found_response \u00b6 Summary \u00b6 The response when a handler could not be found for a method/path not_found_response -> HttpResponse not_found_response : HttpResponse = ... method BasicHttpRouter . add \u00b6 Summary \u00b6 Add an HTTP request handler BasicHttpRouter . add ( methods : AbstractSet[str] , path : str , callback : HttpRequestCallback ) -> Any Parameters \u00b6 methods : AbstractSet[str] The supported HTTP methods. path : str The path. callback : HttpRequestCallback The request handler. Returns \u00b6 Any : method BasicHttpRouter . add_route \u00b6 Summary \u00b6 Add a route to a callback for a method and path definition BasicHttpRouter . add_route ( method : str , path_definition : PathDefinition , callback : HttpRequestCallback ) -> Any Parameters \u00b6 method : str The method. path_definition : PathDefinition The path definition callback : HttpRequestCallback The callback Returns \u00b6 Any : method BasicHttpRouter . resolve \u00b6 Summary \u00b6 Resolve a request to a handler with the route matches BasicHttpRouter . resolve ( method : str , path : str ) -> Tuple[Optional[HttpRequestCallback], Optional[RouteMatches]] Parameters \u00b6 method : str The HTTP method. path : str The path. Returns \u00b6 Tuple[Optional[HttpRequestCallback], Optional[RouteMatches]] : A handler and the optional route matches. module bareasgi.basic_router.web_socket_router \u00b6 Summary \u00b6 A basic Websocket router. class BasicWebSocketRouter ( WebSocketRouter ) \u00b6 Summary \u00b6 The implementation of a basic Websocket router bareasgi.basic_router . BasicWebSocketRouter ( ) -> None method BasicWebSocketRouter . add \u00b6 Summary \u00b6 Add the WebSocket handler for a route BasicWebSocketRouter . add ( path : str , callback : WebSocketRequestCallback ) -> Any Parameters \u00b6 path : str The path. callback : WebSocketRequestCallback The handler Returns \u00b6 Any : method BasicWebSocketRouter . resolve \u00b6 Summary \u00b6 Resolve a route to a handler BasicWebSocketRouter . resolve ( path : str ) -> Tuple[Optional[HttpRequestCallback], Optional[RouteMatches]] Parameters \u00b6 path : str The path Returns \u00b6 Tuple[Optional[HttpRequestCallback], Optional[RouteMatches]] : A handler and possible route matches","title":"bareasgi.basic_router"},{"location":"api/bareasgi.basic_router/#module-bareasgibasic_routerhttp_router","text":"","title":"module bareasgi.basic_router.http_router"},{"location":"api/bareasgi.basic_router/#summary","text":"Http Routing","title":"Summary"},{"location":"api/bareasgi.basic_router/#class-basichttprouterhttprouter","text":"","title":"class BasicHttpRouter(HttpRouter)"},{"location":"api/bareasgi.basic_router/#summary_1","text":"A basic http routing implementation bareasgi.basic_router . BasicHttpRouter ( not_found_response : Union[intTuple[intUnionListTuple[bytes, bytes]], NoneTypeTuple[intUnionListTuple[bytes, bytes]], NoneTypeUnionAsyncIterable[bytes], NoneTypeTuple[intUnionListTuple[bytes, bytes]], NoneTypeUnionAsyncIterable[bytes], NoneTypeUnionIterableTuple[strListTuple[bytes, bytes]]]], NoneType]]] ) -> None","title":"Summary"},{"location":"api/bareasgi.basic_router/#parameters","text":"not_found_response : Union[intTuple[intUnionListTuple[bytes, bytes]], NoneTypeTuple[intUnionListTuple[bytes, bytes]], NoneTypeUnionAsyncIterable[bytes], NoneTypeTuple[intUnionListTuple[bytes, bytes]], NoneTypeUnionAsyncIterable[bytes], NoneTypeUnionIterableTuple[strListTuple[bytes, bytes]]]], NoneType]]]","title":"Parameters"},{"location":"api/bareasgi.basic_router/#property-basichttprouternot_found_response","text":"","title":"property BasicHttpRouter.not_found_response"},{"location":"api/bareasgi.basic_router/#summary_2","text":"The response when a handler could not be found for a method/path not_found_response -> HttpResponse not_found_response : HttpResponse = ...","title":"Summary"},{"location":"api/bareasgi.basic_router/#method-basichttprouteradd","text":"","title":"method BasicHttpRouter.add"},{"location":"api/bareasgi.basic_router/#summary_3","text":"Add an HTTP request handler BasicHttpRouter . add ( methods : AbstractSet[str] , path : str , callback : HttpRequestCallback ) -> Any","title":"Summary"},{"location":"api/bareasgi.basic_router/#parameters_1","text":"methods : AbstractSet[str] The supported HTTP methods. path : str The path. callback : HttpRequestCallback The request handler.","title":"Parameters"},{"location":"api/bareasgi.basic_router/#returns","text":"Any :","title":"Returns"},{"location":"api/bareasgi.basic_router/#method-basichttprouteradd_route","text":"","title":"method BasicHttpRouter.add_route"},{"location":"api/bareasgi.basic_router/#summary_4","text":"Add a route to a callback for a method and path definition BasicHttpRouter . add_route ( method : str , path_definition : PathDefinition , callback : HttpRequestCallback ) -> Any","title":"Summary"},{"location":"api/bareasgi.basic_router/#parameters_2","text":"method : str The method. path_definition : PathDefinition The path definition callback : HttpRequestCallback The callback","title":"Parameters"},{"location":"api/bareasgi.basic_router/#returns_1","text":"Any :","title":"Returns"},{"location":"api/bareasgi.basic_router/#method-basichttprouterresolve","text":"","title":"method BasicHttpRouter.resolve"},{"location":"api/bareasgi.basic_router/#summary_5","text":"Resolve a request to a handler with the route matches BasicHttpRouter . resolve ( method : str , path : str ) -> Tuple[Optional[HttpRequestCallback], Optional[RouteMatches]]","title":"Summary"},{"location":"api/bareasgi.basic_router/#parameters_3","text":"method : str The HTTP method. path : str The path.","title":"Parameters"},{"location":"api/bareasgi.basic_router/#returns_2","text":"Tuple[Optional[HttpRequestCallback], Optional[RouteMatches]] : A handler and the optional route matches.","title":"Returns"},{"location":"api/bareasgi.basic_router/#module-bareasgibasic_routerweb_socket_router","text":"","title":"module bareasgi.basic_router.web_socket_router"},{"location":"api/bareasgi.basic_router/#summary_6","text":"A basic Websocket router.","title":"Summary"},{"location":"api/bareasgi.basic_router/#class-basicwebsocketrouterwebsocketrouter","text":"","title":"class BasicWebSocketRouter(WebSocketRouter)"},{"location":"api/bareasgi.basic_router/#summary_7","text":"The implementation of a basic Websocket router bareasgi.basic_router . BasicWebSocketRouter ( ) -> None","title":"Summary"},{"location":"api/bareasgi.basic_router/#method-basicwebsocketrouteradd","text":"","title":"method BasicWebSocketRouter.add"},{"location":"api/bareasgi.basic_router/#summary_8","text":"Add the WebSocket handler for a route BasicWebSocketRouter . add ( path : str , callback : WebSocketRequestCallback ) -> Any","title":"Summary"},{"location":"api/bareasgi.basic_router/#parameters_4","text":"path : str The path. callback : WebSocketRequestCallback The handler","title":"Parameters"},{"location":"api/bareasgi.basic_router/#returns_3","text":"Any :","title":"Returns"},{"location":"api/bareasgi.basic_router/#method-basicwebsocketrouterresolve","text":"","title":"method BasicWebSocketRouter.resolve"},{"location":"api/bareasgi.basic_router/#summary_9","text":"Resolve a route to a handler BasicWebSocketRouter . resolve ( path : str ) -> Tuple[Optional[HttpRequestCallback], Optional[RouteMatches]]","title":"Summary"},{"location":"api/bareasgi.basic_router/#parameters_5","text":"path : str The path","title":"Parameters"},{"location":"api/bareasgi.basic_router/#returns_4","text":"Tuple[Optional[HttpRequestCallback], Optional[RouteMatches]] : A handler and possible route matches","title":"Returns"},{"location":"api/bareasgi/","text":"class Application \u00b6 Summary \u00b6 Construct the application Description \u00b6 from bareasgi import ( Application , Scope , Info , RouteMatches , Content , WebSocket , text_reader , text_writer ) async def http_request_callback ( scope : Scope , info : Info , matches : RouteMatches , content : Content ) -> HttpResponse : text = await text_reader ( content ) return 200 , [( b 'content-type' , b 'text/plain' )], text_writer ( 'This is not a test' ), None import uvicorn app = Application () app . http_router . add ({ 'GET' , 'POST' , 'PUT' , 'DELETE' }, '/ {path} ' , http_request_callback ) uvicorn . run ( app , port = 9009 ) bareasgi . Application ( * , middlewares : Optional[List[HttpMiddlewareCallback]] , http_router : Optional[HttpRouter] , web_socket_router : Optional[WebSocketRouter] , startup_handlers : Optional[List[LifespanHandler]] , shutdown_handlers : Optional[List[LifespanHandler]] , not_found_response : Optional[HttpResponse] , info : Optional[MutableMapping[str, Any]] ) -> None Parameters \u00b6 middlewares : Optional[List[HttpMiddlewareCallback]] (optional) Optional middleware callbacks. Defaults to None. http_router : Optional[HttpRouter] (optional) Optional router to for http routes. Defaults to None. web_socket_router : Optional[WebSocketRouter] (optional) Optional router for web routes. Defaults to None. startup_handlers : Optional[List[LifespanHandler]] (optional) Optional handlers to run at startup. Defaults to None. shutdown_handlers : Optional[List[LifespanHandler]] (optional) Optional handlers to run at shutdown. Defaults to None. not_found_response : Optional[HttpResponse] (optional) Optional not found (404) response. Defaults to None. info : Optional[MutableMapping[str, Any]] (optional) Optional dictionary for user data. Defaults to None. property Application . http_router \u00b6 Summary \u00b6 Router for http routes http_router -> HttpRouter property Application . info \u00b6 Summary \u00b6 A place to sto application specific data. info -> MutableMapping[str, Any] property Application . middlewares \u00b6 Summary \u00b6 The middlewares. middlewares -> List[HttpMiddlewareCallback] property Application . shutdown_handlers \u00b6 Summary \u00b6 Handlers run on shutdown shutdown_handlers -> List[LifespanHandler] property Application . startup_handlers \u00b6 Summary \u00b6 Handlers run at startup startup_handlers -> List[LifespanHandler] property Application . ws_router \u00b6 Summary \u00b6 Router for WebSocket routes ws_router -> WebSocketRouter method Application . on_http_request \u00b6 Summary \u00b6 A decorator to add an http route handler to the application Application . on_http_request ( methods : AbstractSet[str] , path : str ) -> Callable[[HttpRequestCallback], HttpRequestCallback] Parameters \u00b6 methods : AbstractSet[str] The http methods, e.g. {{'POST', 'PUT'} path : str The path Returns \u00b6 Callable[[HttpRequestCallback], HttpRequestCallback] : The decorated request. method Application . on_shutdown \u00b6 Summary \u00b6 A decorator to add a startup handler to the application Application . on_shutdown ( callback : LifespanHandler ) -> Callable[[LifespanHandler], LifespanHandler] Parameters \u00b6 callback : LifespanHandler The shutdown handler. Returns \u00b6 Callable[[LifespanHandler], LifespanHandler] : The decorated handler. method Application . on_startup \u00b6 Summary \u00b6 A decorator to add a startup handler to the application Application . on_startup ( callback : LifespanHandler ) -> Callable[[LifespanHandler], LifespanHandler] Parameters \u00b6 callback : LifespanHandler The startup handler. Returns \u00b6 Callable[[LifespanHandler], LifespanHandler] : The decorated handler. method Application . on_ws_request \u00b6 Summary \u00b6 A decorator to add a websocket route handler to the application Application . on_ws_request ( path : str ) -> Callable[[WebSocketRequestCallback], WebSocketRequestCallback] Parameters \u00b6 path : str The path Returns \u00b6 Callable[[WebSocketRequestCallback], WebSocketRequestCallback] : The decorated handler","title":"bareasgi"},{"location":"api/bareasgi/#class-application","text":"","title":"class Application"},{"location":"api/bareasgi/#summary","text":"Construct the application","title":"Summary"},{"location":"api/bareasgi/#description","text":"from bareasgi import ( Application , Scope , Info , RouteMatches , Content , WebSocket , text_reader , text_writer ) async def http_request_callback ( scope : Scope , info : Info , matches : RouteMatches , content : Content ) -> HttpResponse : text = await text_reader ( content ) return 200 , [( b 'content-type' , b 'text/plain' )], text_writer ( 'This is not a test' ), None import uvicorn app = Application () app . http_router . add ({ 'GET' , 'POST' , 'PUT' , 'DELETE' }, '/ {path} ' , http_request_callback ) uvicorn . run ( app , port = 9009 ) bareasgi . Application ( * , middlewares : Optional[List[HttpMiddlewareCallback]] , http_router : Optional[HttpRouter] , web_socket_router : Optional[WebSocketRouter] , startup_handlers : Optional[List[LifespanHandler]] , shutdown_handlers : Optional[List[LifespanHandler]] , not_found_response : Optional[HttpResponse] , info : Optional[MutableMapping[str, Any]] ) -> None","title":"Description"},{"location":"api/bareasgi/#parameters","text":"middlewares : Optional[List[HttpMiddlewareCallback]] (optional) Optional middleware callbacks. Defaults to None. http_router : Optional[HttpRouter] (optional) Optional router to for http routes. Defaults to None. web_socket_router : Optional[WebSocketRouter] (optional) Optional router for web routes. Defaults to None. startup_handlers : Optional[List[LifespanHandler]] (optional) Optional handlers to run at startup. Defaults to None. shutdown_handlers : Optional[List[LifespanHandler]] (optional) Optional handlers to run at shutdown. Defaults to None. not_found_response : Optional[HttpResponse] (optional) Optional not found (404) response. Defaults to None. info : Optional[MutableMapping[str, Any]] (optional) Optional dictionary for user data. Defaults to None.","title":"Parameters"},{"location":"api/bareasgi/#property-applicationhttp_router","text":"","title":"property Application.http_router"},{"location":"api/bareasgi/#summary_1","text":"Router for http routes http_router -> HttpRouter","title":"Summary"},{"location":"api/bareasgi/#property-applicationinfo","text":"","title":"property Application.info"},{"location":"api/bareasgi/#summary_2","text":"A place to sto application specific data. info -> MutableMapping[str, Any]","title":"Summary"},{"location":"api/bareasgi/#property-applicationmiddlewares","text":"","title":"property Application.middlewares"},{"location":"api/bareasgi/#summary_3","text":"The middlewares. middlewares -> List[HttpMiddlewareCallback]","title":"Summary"},{"location":"api/bareasgi/#property-applicationshutdown_handlers","text":"","title":"property Application.shutdown_handlers"},{"location":"api/bareasgi/#summary_4","text":"Handlers run on shutdown shutdown_handlers -> List[LifespanHandler]","title":"Summary"},{"location":"api/bareasgi/#property-applicationstartup_handlers","text":"","title":"property Application.startup_handlers"},{"location":"api/bareasgi/#summary_5","text":"Handlers run at startup startup_handlers -> List[LifespanHandler]","title":"Summary"},{"location":"api/bareasgi/#property-applicationws_router","text":"","title":"property Application.ws_router"},{"location":"api/bareasgi/#summary_6","text":"Router for WebSocket routes ws_router -> WebSocketRouter","title":"Summary"},{"location":"api/bareasgi/#method-applicationon_http_request","text":"","title":"method Application.on_http_request"},{"location":"api/bareasgi/#summary_7","text":"A decorator to add an http route handler to the application Application . on_http_request ( methods : AbstractSet[str] , path : str ) -> Callable[[HttpRequestCallback], HttpRequestCallback]","title":"Summary"},{"location":"api/bareasgi/#parameters_1","text":"methods : AbstractSet[str] The http methods, e.g. {{'POST', 'PUT'} path : str The path","title":"Parameters"},{"location":"api/bareasgi/#returns","text":"Callable[[HttpRequestCallback], HttpRequestCallback] : The decorated request.","title":"Returns"},{"location":"api/bareasgi/#method-applicationon_shutdown","text":"","title":"method Application.on_shutdown"},{"location":"api/bareasgi/#summary_8","text":"A decorator to add a startup handler to the application Application . on_shutdown ( callback : LifespanHandler ) -> Callable[[LifespanHandler], LifespanHandler]","title":"Summary"},{"location":"api/bareasgi/#parameters_2","text":"callback : LifespanHandler The shutdown handler.","title":"Parameters"},{"location":"api/bareasgi/#returns_1","text":"Callable[[LifespanHandler], LifespanHandler] : The decorated handler.","title":"Returns"},{"location":"api/bareasgi/#method-applicationon_startup","text":"","title":"method Application.on_startup"},{"location":"api/bareasgi/#summary_9","text":"A decorator to add a startup handler to the application Application . on_startup ( callback : LifespanHandler ) -> Callable[[LifespanHandler], LifespanHandler]","title":"Summary"},{"location":"api/bareasgi/#parameters_3","text":"callback : LifespanHandler The startup handler.","title":"Parameters"},{"location":"api/bareasgi/#returns_2","text":"Callable[[LifespanHandler], LifespanHandler] : The decorated handler.","title":"Returns"},{"location":"api/bareasgi/#method-applicationon_ws_request","text":"","title":"method Application.on_ws_request"},{"location":"api/bareasgi/#summary_10","text":"A decorator to add a websocket route handler to the application Application . on_ws_request ( path : str ) -> Callable[[WebSocketRequestCallback], WebSocketRequestCallback]","title":"Summary"},{"location":"api/bareasgi/#parameters_4","text":"path : str The path","title":"Parameters"},{"location":"api/bareasgi/#returns_3","text":"Callable[[WebSocketRequestCallback], WebSocketRequestCallback] : The decorated handler","title":"Returns"},{"location":"tutorial/","text":"bareASGI-tutorial \u00b6 A tutorial for the bareASGI web framework. Table of contents \u00b6 Getting started Simple REST Lifespan Background Tasks HTTPS Middleware WebSockets Headers (including cookies) Cross-Origin Resource Sharing (CORS) Jinja2 Templating Serving Static Files Server Sent Events Streaming fetch Compression Controller Classes Exceptions","title":"bareASGI-tutorial"},{"location":"tutorial/#bareasgi-tutorial","text":"A tutorial for the bareASGI web framework.","title":"bareASGI-tutorial"},{"location":"tutorial/#table-of-contents","text":"Getting started Simple REST Lifespan Background Tasks HTTPS Middleware WebSockets Headers (including cookies) Cross-Origin Resource Sharing (CORS) Jinja2 Templating Serving Static Files Server Sent Events Streaming fetch Compression Controller Classes Exceptions","title":"Table of contents"},{"location":"tutorial/background-tasks/","text":"Background Tasks \u00b6 Some times it is necessary to run background tasks. For example to poll a data source, or listen to a data stream. The following example starts a background task when the server starts up, then gracefully terminates it when the server shuts down. The source code for the following example can be found here (and here here with typing). The Task \u00b6 The following code provides a dummy task, which just waits for a second then gets the time. This time I've used the typed code. async def time_ticker ( info : Info , shutdown_event : Event ) -> None : print ( 'Starting the time ticker' ) while not shutdown_event . is_set (): info [ 'now' ] = datetime . now () print ( f \"time: { info [ 'now' ] } \" ) try : await asyncio . wait_for ( shutdown_event . wait (), timeout = 1 ) except asyncio . TimeoutError : print ( 'Timeout - normal behaviour when waiting with a timeout' ) except : print ( 'Failure - we should not see this exception' ) print ( 'The time ticker has stopped' ) Rather than simply cancelling the task, I've used the asyncio Event to shutdown more gracefully. The Startup Handler \u00b6 First we create the event and store it in the application's info . Then we create the task with asyncio.create_task and store the task in the application's info . When the task is created it will be scheduled to run. Any time the task awaits , it gives up control and other tasks which are ready to run can proceed. async def time_ticker_startup_handler ( scope , info , request ): # Create an event that can be set when the background task should shutdown. shutdown_event = Event () info [ 'shutdown_event' ] = shutdown_event # Create the background task. info [ 'time_ticker_task' ] = asyncio . create_task ( time_ticker ( info , shutdown_event ) ) Note that the shutdown event was created in the startup handler. This is critical . I'll discuss why in the \"Gotcha!\" section. The Shutdown Handler \u00b6 Here is the code for the shutdown handler. async def time_ticker_shutdown_handler ( scope , info , request ): # Set the shutdown event so the background task can stop gracefully. shutdown_event : Event = info [ 'shutdown_event' ] shutdown_event . set () # Wait for the background task to finish. time_ticker_task : asyncio . Task = info [ 'time_ticker_task' ] await time_ticker_task First we retrieve the event from the application's info and set it. In the background task the loop will exit when it next checks the event. while not shutdown_event . is_set (): ... Next we fetch the task from the applications info and await it. When the next timeout occurs in the background task it will exit it's loop, and the background task gracefully shuts down. The Program \u00b6 Here is the full code. I've added a request handler which returns the time stored by the background task to demonstrate that the web server is still able to handle requests. import asyncio from asyncio import Event from datetime import datetime import logging import uvicorn from bareasgi import Application , text_writer logging . basicConfig ( level = logging . DEBUG ) LOGGER = logging . getLogger ( 'background_tasks' ) async def time_ticker ( info , shutdown_event ): LOGGER . debug ( 'Starting the time ticker' ) while not shutdown_event . is_set (): # Store the time info [ 'now' ] = datetime . now () LOGGER . debug ( 'time: %s ' , info [ 'now' ]) try : await asyncio . wait_for ( shutdown_event . wait (), timeout = 1 ) except asyncio . TimeoutError : LOGGER . debug ( 'Timeout - normal behaviour when waiting with a timeout' ) except : LOGGER . exception ( 'Failure - we should not see this exception' ) LOGGER . debug ( 'The time ticker has stopped' ) async def time_ticker_startup_handler ( scope , info , request ): # Create an event that can be set when the background task should shutdown. shutdown_event = Event () info [ 'shutdown_event' ] = shutdown_event # Create the background task. info [ 'time_ticker_task' ] = asyncio . create_task ( time_ticker ( info , shutdown_event ) ) async def time_ticker_shutdown_handler ( scope , info , request ): # Set the shutdown event so the background task can stop gracefully. shutdown_event : Event = info [ 'shutdown_event' ] LOGGER . debug ( 'Stopping the time_ticker' ) shutdown_event . set () # Wait for the background task to finish. time_ticker_task : asyncio . Task = info [ 'time_ticker_task' ] LOGGER . debug ( 'Waiting for time_ticker' ) await time_ticker_task LOGGER . debug ( 'time_ticker shutdown' ) async def http_request_callback ( scope , info , matches , content ): headers = [ ( b 'content-type' , b 'text/plain' ) ] return 200 , headers , text_writer ( f \"Last time tick: { info . get ( 'now' ) } \" ) app = Application ( startup_handlers = [ time_ticker_startup_handler ], shutdown_handlers = [ time_ticker_shutdown_handler ] ) app . http_router . add ({ 'GET' }, '/{rest:path}' , http_request_callback ) uvicorn . run ( app , port = 9009 ) Canceling \u00b6 Rather than using an event we could have just cancelled the task. async def time_ticker_shutdown_handler ( scope , info , request ): time_ticker_task : asyncio . Task = info [ 'time_ticker_task' ] try : time_ticker_task . cancel () await time_ticker_task except asyncio . CancellationError : pass The background task might then look as follows. async def time_ticker ( info , shutdown_event ): while True : # Store the time info [ 'now' ] = datetime . now () print ( f \"time: { info [ 'now' ] } \" ) try : await asyncio . sleep ( 1 ) except asyncio . CancellationError : return # Catch the task.cancel() and exit except : print ( 'Failure - we should not see this exception' ) print ( 'The time ticker has stopped' ) Cancel or Shutdown Event? \u00b6 In the above example cancelling the task would have been appropriate. Nothing bad would happen, and no data would be lost. The event approach is useful where cancelling the task would result in some kind of corrupt state. For example if a database write was in progress, or a message queue was being serviced. Gotcha! \u00b6 If we had a large program running many background tasks with multiple startup handlers, it would seem reasonable to create the shutdown event right at the start. # This won't work! app = Application ( info = { 'shutdown_event' : asyncio . Event ()}) Unfortunately this won't work and will lead to hours of frustration. When an ASGI server starts it creates a new event loop. However the asyncio.Event() call attached the event to the existing event loop. At the point the event is awaited you will get an error telling you the coroutine was attached to another event loop, which is true, but not helpful! This is true for anything that can be awaited. They must all be created in the context of the ASGI server's event loop. What next? \u00b6 Either go back to the table of contents or go to the https tutorial.","title":"Background Tasks"},{"location":"tutorial/background-tasks/#background-tasks","text":"Some times it is necessary to run background tasks. For example to poll a data source, or listen to a data stream. The following example starts a background task when the server starts up, then gracefully terminates it when the server shuts down. The source code for the following example can be found here (and here here with typing).","title":"Background Tasks"},{"location":"tutorial/background-tasks/#the-task","text":"The following code provides a dummy task, which just waits for a second then gets the time. This time I've used the typed code. async def time_ticker ( info : Info , shutdown_event : Event ) -> None : print ( 'Starting the time ticker' ) while not shutdown_event . is_set (): info [ 'now' ] = datetime . now () print ( f \"time: { info [ 'now' ] } \" ) try : await asyncio . wait_for ( shutdown_event . wait (), timeout = 1 ) except asyncio . TimeoutError : print ( 'Timeout - normal behaviour when waiting with a timeout' ) except : print ( 'Failure - we should not see this exception' ) print ( 'The time ticker has stopped' ) Rather than simply cancelling the task, I've used the asyncio Event to shutdown more gracefully.","title":"The Task"},{"location":"tutorial/background-tasks/#the-startup-handler","text":"First we create the event and store it in the application's info . Then we create the task with asyncio.create_task and store the task in the application's info . When the task is created it will be scheduled to run. Any time the task awaits , it gives up control and other tasks which are ready to run can proceed. async def time_ticker_startup_handler ( scope , info , request ): # Create an event that can be set when the background task should shutdown. shutdown_event = Event () info [ 'shutdown_event' ] = shutdown_event # Create the background task. info [ 'time_ticker_task' ] = asyncio . create_task ( time_ticker ( info , shutdown_event ) ) Note that the shutdown event was created in the startup handler. This is critical . I'll discuss why in the \"Gotcha!\" section.","title":"The Startup Handler"},{"location":"tutorial/background-tasks/#the-shutdown-handler","text":"Here is the code for the shutdown handler. async def time_ticker_shutdown_handler ( scope , info , request ): # Set the shutdown event so the background task can stop gracefully. shutdown_event : Event = info [ 'shutdown_event' ] shutdown_event . set () # Wait for the background task to finish. time_ticker_task : asyncio . Task = info [ 'time_ticker_task' ] await time_ticker_task First we retrieve the event from the application's info and set it. In the background task the loop will exit when it next checks the event. while not shutdown_event . is_set (): ... Next we fetch the task from the applications info and await it. When the next timeout occurs in the background task it will exit it's loop, and the background task gracefully shuts down.","title":"The Shutdown Handler"},{"location":"tutorial/background-tasks/#the-program","text":"Here is the full code. I've added a request handler which returns the time stored by the background task to demonstrate that the web server is still able to handle requests. import asyncio from asyncio import Event from datetime import datetime import logging import uvicorn from bareasgi import Application , text_writer logging . basicConfig ( level = logging . DEBUG ) LOGGER = logging . getLogger ( 'background_tasks' ) async def time_ticker ( info , shutdown_event ): LOGGER . debug ( 'Starting the time ticker' ) while not shutdown_event . is_set (): # Store the time info [ 'now' ] = datetime . now () LOGGER . debug ( 'time: %s ' , info [ 'now' ]) try : await asyncio . wait_for ( shutdown_event . wait (), timeout = 1 ) except asyncio . TimeoutError : LOGGER . debug ( 'Timeout - normal behaviour when waiting with a timeout' ) except : LOGGER . exception ( 'Failure - we should not see this exception' ) LOGGER . debug ( 'The time ticker has stopped' ) async def time_ticker_startup_handler ( scope , info , request ): # Create an event that can be set when the background task should shutdown. shutdown_event = Event () info [ 'shutdown_event' ] = shutdown_event # Create the background task. info [ 'time_ticker_task' ] = asyncio . create_task ( time_ticker ( info , shutdown_event ) ) async def time_ticker_shutdown_handler ( scope , info , request ): # Set the shutdown event so the background task can stop gracefully. shutdown_event : Event = info [ 'shutdown_event' ] LOGGER . debug ( 'Stopping the time_ticker' ) shutdown_event . set () # Wait for the background task to finish. time_ticker_task : asyncio . Task = info [ 'time_ticker_task' ] LOGGER . debug ( 'Waiting for time_ticker' ) await time_ticker_task LOGGER . debug ( 'time_ticker shutdown' ) async def http_request_callback ( scope , info , matches , content ): headers = [ ( b 'content-type' , b 'text/plain' ) ] return 200 , headers , text_writer ( f \"Last time tick: { info . get ( 'now' ) } \" ) app = Application ( startup_handlers = [ time_ticker_startup_handler ], shutdown_handlers = [ time_ticker_shutdown_handler ] ) app . http_router . add ({ 'GET' }, '/{rest:path}' , http_request_callback ) uvicorn . run ( app , port = 9009 )","title":"The Program"},{"location":"tutorial/background-tasks/#canceling","text":"Rather than using an event we could have just cancelled the task. async def time_ticker_shutdown_handler ( scope , info , request ): time_ticker_task : asyncio . Task = info [ 'time_ticker_task' ] try : time_ticker_task . cancel () await time_ticker_task except asyncio . CancellationError : pass The background task might then look as follows. async def time_ticker ( info , shutdown_event ): while True : # Store the time info [ 'now' ] = datetime . now () print ( f \"time: { info [ 'now' ] } \" ) try : await asyncio . sleep ( 1 ) except asyncio . CancellationError : return # Catch the task.cancel() and exit except : print ( 'Failure - we should not see this exception' ) print ( 'The time ticker has stopped' )","title":"Canceling"},{"location":"tutorial/background-tasks/#cancel-or-shutdown-event","text":"In the above example cancelling the task would have been appropriate. Nothing bad would happen, and no data would be lost. The event approach is useful where cancelling the task would result in some kind of corrupt state. For example if a database write was in progress, or a message queue was being serviced.","title":"Cancel or Shutdown Event?"},{"location":"tutorial/background-tasks/#gotcha","text":"If we had a large program running many background tasks with multiple startup handlers, it would seem reasonable to create the shutdown event right at the start. # This won't work! app = Application ( info = { 'shutdown_event' : asyncio . Event ()}) Unfortunately this won't work and will lead to hours of frustration. When an ASGI server starts it creates a new event loop. However the asyncio.Event() call attached the event to the existing event loop. At the point the event is awaited you will get an error telling you the coroutine was attached to another event loop, which is true, but not helpful! This is true for anything that can be awaited. They must all be created in the context of the ASGI server's event loop.","title":"Gotcha!"},{"location":"tutorial/background-tasks/#what-next","text":"Either go back to the table of contents or go to the https tutorial.","title":"What next?"},{"location":"tutorial/compression/","text":"Compression \u00b6 Compression can be added through middleware. The source code for the following example can be found here (and here here with typing). The middleware can be added as follows. from bareutils.compression import make_default_compression_middleware compression_middleware = make_default_compression_middleware ( minimum_size = 1024 ) app = Application ( middlewares = [ compression_middleware ]) The middleware will then be applied according to the headers of the client that made the request. What next? \u00b6 Either go back to the table of contents or go to the controller classes tutorial.","title":"Compression"},{"location":"tutorial/compression/#compression","text":"Compression can be added through middleware. The source code for the following example can be found here (and here here with typing). The middleware can be added as follows. from bareutils.compression import make_default_compression_middleware compression_middleware = make_default_compression_middleware ( minimum_size = 1024 ) app = Application ( middlewares = [ compression_middleware ]) The middleware will then be applied according to the headers of the client that made the request.","title":"Compression"},{"location":"tutorial/compression/#what-next","text":"Either go back to the table of contents or go to the controller classes tutorial.","title":"What next?"},{"location":"tutorial/controller-classes/","text":"Controller Classes \u00b6 Sometimes it can be useful to group route handlers into a class, commonly called a controller . This is often done when the controller has some state, or dedicated access to a resource. For example a blog post controller might hold a the instance of a blog post repository. The source code for the following example can be found here (and here here with typing). The following snippet shows a trival example: import json from bareasgi import Application , text_reader , text_writer import uvicorn class InfoController : def add_routes ( self , app ): app . http_router . add ({ 'GET' }, '/info' , self . get_info ) app . http_router . add ({ 'POST' }, '/info' , self . set_info ) async def get_info ( self , scope , info , matches , content ): text = json . dumps ( info ) return 200 , [( b 'content-type' , b 'application/json' )], text_writer ( text ) async def set_info ( self , scope , info , matches , content ): text = await text_reader ( content ) data = json . loads ( text ) info . update ( data ) return 204 application = Application ( info = { 'name' : 'Michael Caine' }) info_controller = InfoController () info_controller . add_routes ( application ) uvicorn . run ( application , port = 9009 ) What next? \u00b6 Either go back to the table of contents or go to the exceptions tutorial.","title":"Controller Classes"},{"location":"tutorial/controller-classes/#controller-classes","text":"Sometimes it can be useful to group route handlers into a class, commonly called a controller . This is often done when the controller has some state, or dedicated access to a resource. For example a blog post controller might hold a the instance of a blog post repository. The source code for the following example can be found here (and here here with typing). The following snippet shows a trival example: import json from bareasgi import Application , text_reader , text_writer import uvicorn class InfoController : def add_routes ( self , app ): app . http_router . add ({ 'GET' }, '/info' , self . get_info ) app . http_router . add ({ 'POST' }, '/info' , self . set_info ) async def get_info ( self , scope , info , matches , content ): text = json . dumps ( info ) return 200 , [( b 'content-type' , b 'application/json' )], text_writer ( text ) async def set_info ( self , scope , info , matches , content ): text = await text_reader ( content ) data = json . loads ( text ) info . update ( data ) return 204 application = Application ( info = { 'name' : 'Michael Caine' }) info_controller = InfoController () info_controller . add_routes ( application ) uvicorn . run ( application , port = 9009 )","title":"Controller Classes"},{"location":"tutorial/controller-classes/#what-next","text":"Either go back to the table of contents or go to the exceptions tutorial.","title":"What next?"},{"location":"tutorial/cors/","text":"Cross-Origin Resource Sharing \u00b6 Cross-Origin Resource Sharing (CORS) is a way for a server to allow a client to access it's data in a browser. To demonstrate the functionality we will need two web servers. One to provide data, and a second to request the data. The source code for the REST server can be found here (and here here with typing). The source code for the web server can be found here (and here here with typing) with the html here . REST Server \u00b6 There is very little required to add CORS support. All you need to do is add the middleware. from bareasgi import Application , text_reader , text_writer from bareasgi_cors import CORSMiddleware cors_middleware = CORSMiddleware () app = Application ( middlewares = [ cors_middleware ] ) POST requests \u00b6 When a browser makes a cross origin POST it will first make an OPTIONS request. Some web frameworks will transparently handle this, but in the \"bare\" tradition of this framework it is left to the developer to decide this. However, typically, if you have added CORS support you probably wanted to add the OPTIONS method to any POST route. cors_middleware = CORSMiddleware () app = Application ( info = { 'name' : 'Michael Caine' }, middlewares = [ cors_middleware ] ) app . http_router . add ({ 'GET' }, '/info' , get_info ) app . http_router . add ({ 'POST' , 'OPTIONS' }, '/info' , set_info ) Note that this is not required on a GET . Web Server \u00b6 The web server doesn't need to do anything special. The page the web server provides calls a GET when the page loads. window . onload = function () { fetch ( 'http://127.0.0.1:9010/info' ) . then ( function ( response ) { return response . json (); }) . then ( function ( info ) { const element = document . getElementById ( 'info' ); element . value = info . name ; }); } And when the form is submitted it makes a POST . fetch ( 'http://127.0.0.1:9010/info' , { method : 'POST' , headers : { 'Content-Type' : 'application/json' }, body : JSON . stringify ( data ) }) . then ( function ( response ) { console . log ( response ); return Promise . resolve ( 'Done' ); }); You can check that it's working by commenting out the CORS middleware in the REST server. The browser will reject the fetch requests. What next? \u00b6 Either go back to the table of contents or go to Exceptions .","title":"Cross-Origin Resource Sharing"},{"location":"tutorial/cors/#cross-origin-resource-sharing","text":"Cross-Origin Resource Sharing (CORS) is a way for a server to allow a client to access it's data in a browser. To demonstrate the functionality we will need two web servers. One to provide data, and a second to request the data. The source code for the REST server can be found here (and here here with typing). The source code for the web server can be found here (and here here with typing) with the html here .","title":"Cross-Origin Resource Sharing"},{"location":"tutorial/cors/#rest-server","text":"There is very little required to add CORS support. All you need to do is add the middleware. from bareasgi import Application , text_reader , text_writer from bareasgi_cors import CORSMiddleware cors_middleware = CORSMiddleware () app = Application ( middlewares = [ cors_middleware ] )","title":"REST Server"},{"location":"tutorial/cors/#post-requests","text":"When a browser makes a cross origin POST it will first make an OPTIONS request. Some web frameworks will transparently handle this, but in the \"bare\" tradition of this framework it is left to the developer to decide this. However, typically, if you have added CORS support you probably wanted to add the OPTIONS method to any POST route. cors_middleware = CORSMiddleware () app = Application ( info = { 'name' : 'Michael Caine' }, middlewares = [ cors_middleware ] ) app . http_router . add ({ 'GET' }, '/info' , get_info ) app . http_router . add ({ 'POST' , 'OPTIONS' }, '/info' , set_info ) Note that this is not required on a GET .","title":"POST requests"},{"location":"tutorial/cors/#web-server","text":"The web server doesn't need to do anything special. The page the web server provides calls a GET when the page loads. window . onload = function () { fetch ( 'http://127.0.0.1:9010/info' ) . then ( function ( response ) { return response . json (); }) . then ( function ( info ) { const element = document . getElementById ( 'info' ); element . value = info . name ; }); } And when the form is submitted it makes a POST . fetch ( 'http://127.0.0.1:9010/info' , { method : 'POST' , headers : { 'Content-Type' : 'application/json' }, body : JSON . stringify ( data ) }) . then ( function ( response ) { console . log ( response ); return Promise . resolve ( 'Done' ); }); You can check that it's working by commenting out the CORS middleware in the REST server. The browser will reject the fetch requests.","title":"Web Server"},{"location":"tutorial/cors/#what-next","text":"Either go back to the table of contents or go to Exceptions .","title":"What next?"},{"location":"tutorial/exceptions/","text":"Exceptions \u00b6 The bareASGI framework handles the exception of type urllib.error.HTTPError . The source code for the following example can be found here (and here here with typing). If the content of the exception is specified it may be either an asynchronous iterator yielding bytes, a string or a bytes. Here are some examples. from urllib.error import HTTPError from bareasgi import Application , text_writer import bareutils.header as header import pkg_resources import uvicorn def make_url ( scope ) -> str : host = header . find ( b 'host' , scope [ 'headers' ], b 'unknown' ) . decode () return f \" { scope [ 'scheme' ] } :// { host }{ scope [ 'path' ] } \" async def index_handler ( scope , info , matches , content ): headers = [ ( b 'content-type' , b 'text/html' ) ] return 200 , headers , text_writer ( info [ 'html' ]) async def raise_none_exception ( scope , info , matches , content ): raise HTTPError ( make_url ( scope ), 401 , None , None , None ) async def raise_text_exception ( scope , info , matches , content ): raise HTTPError ( make_url ( scope ), 401 , 'Unauthorized - text' , [( b 'content-type' , b 'text/plain' )], None ) async def raise_bytes_exception ( scope , info , matches , content ): raise HTTPError ( make_url ( scope ), 401 , b 'Unauthorized - bytes' , [( b 'content-type' , b 'text/plain' )], None ) async def raise_writer_exception ( scope , info , matches , content ): raise HTTPError ( make_url ( scope ), 401 , text_writer ( 'Unauthorized - writer' ), [( b 'content-type' , b 'text/plain' )], None ) html_filename = pkg_resources . resource_filename ( __name__ , \"server_sent_events.html\" ) with open ( html_filename , 'rt' ) as file_ptr : html = file_ptr . read () app = Application ( info = dict ( html = html )) app . http_router . add ({ 'GET' }, '/' , index_handler ) app . http_router . add ({ 'GET' }, '/raise_none_exception' , raise_none_exception ) app . http_router . add ({ 'GET' }, '/raise_text_exception' , raise_text_exception ) app . http_router . add ({ 'GET' }, '/raise_bytes_exception' , raise_bytes_exception ) app . http_router . add ({ 'GET' }, '/raise_writer_exception' , raise_writer_exception ) uvicorn . run ( app , port = 9009 )","title":"Exceptions"},{"location":"tutorial/exceptions/#exceptions","text":"The bareASGI framework handles the exception of type urllib.error.HTTPError . The source code for the following example can be found here (and here here with typing). If the content of the exception is specified it may be either an asynchronous iterator yielding bytes, a string or a bytes. Here are some examples. from urllib.error import HTTPError from bareasgi import Application , text_writer import bareutils.header as header import pkg_resources import uvicorn def make_url ( scope ) -> str : host = header . find ( b 'host' , scope [ 'headers' ], b 'unknown' ) . decode () return f \" { scope [ 'scheme' ] } :// { host }{ scope [ 'path' ] } \" async def index_handler ( scope , info , matches , content ): headers = [ ( b 'content-type' , b 'text/html' ) ] return 200 , headers , text_writer ( info [ 'html' ]) async def raise_none_exception ( scope , info , matches , content ): raise HTTPError ( make_url ( scope ), 401 , None , None , None ) async def raise_text_exception ( scope , info , matches , content ): raise HTTPError ( make_url ( scope ), 401 , 'Unauthorized - text' , [( b 'content-type' , b 'text/plain' )], None ) async def raise_bytes_exception ( scope , info , matches , content ): raise HTTPError ( make_url ( scope ), 401 , b 'Unauthorized - bytes' , [( b 'content-type' , b 'text/plain' )], None ) async def raise_writer_exception ( scope , info , matches , content ): raise HTTPError ( make_url ( scope ), 401 , text_writer ( 'Unauthorized - writer' ), [( b 'content-type' , b 'text/plain' )], None ) html_filename = pkg_resources . resource_filename ( __name__ , \"server_sent_events.html\" ) with open ( html_filename , 'rt' ) as file_ptr : html = file_ptr . read () app = Application ( info = dict ( html = html )) app . http_router . add ({ 'GET' }, '/' , index_handler ) app . http_router . add ({ 'GET' }, '/raise_none_exception' , raise_none_exception ) app . http_router . add ({ 'GET' }, '/raise_text_exception' , raise_text_exception ) app . http_router . add ({ 'GET' }, '/raise_bytes_exception' , raise_bytes_exception ) app . http_router . add ({ 'GET' }, '/raise_writer_exception' , raise_writer_exception ) uvicorn . run ( app , port = 9009 )","title":"Exceptions"},{"location":"tutorial/getting-started/","text":"Getting Started with bareASGI \u00b6 Prerequisites \u00b6 ASGI Servers \u00b6 The bareASGI package is a web framework package for ASGI servers, so the first thing required is a server. The servers I have been using are: hypercorn uvicorn At the time of writing hypercorn has the best support for HTTP/2, while uvicorn is the most simple to use. Checkout the links above for installation instructions, The examples will use both servers. bareASGI \u00b6 Finally we must install bareASGI. The bare libraries use poetry , but you can just use pip if you prefer. $ pip install bareasgi Visual Studio Code \u00b6 I use Visual Studio Code as my development environment, and I have left the .vscode files with my settings and launch configurations. Hello, World! \u00b6 Here's a simple hello world program with a link to the source code here , and here here with typing. import uvicorn from bareasgi import Application , bytes_writer app = Application () @app . on_http_request ({ 'GET' }, '/' ) async def http_request_handler ( scope , info , matches , content ): return 200 , [( b 'content-type' , b 'text/plain' )], bytes_writer ( b 'Hello, World!' ) uvicorn . run ( app , port = 9009 ) Browsing to http://localhost:9009 will show \"Hello, World!\". Now let\u2019s take this apart. The HTTP Request Handler \u00b6 As it\u2019s name suggests the http_request_handler function handles an HTTP request . It\u2019s arguments form the request, and it returns a response . Unlike other frameworks I chose not to wrap these in an object. There aren\u2019t many, and I took the view that the less work done that isn\u2019t strictly necessary the faster the framework would be. This example doesn\u2019t use any of the input parameters, so I\u2019ll introduce them later, but it does return a whole lot of stuff for the response. The HTTP Response \u00b6 The first element of the response tuple is the 200 HTTP response code . The second element are the headers. These are optional (we could have passed in None), but we\u2019re returning plain text so I set the content-type accordingly. Note that the headers are a list of tuples of bytes. Also the header name is in lower case. This is all part of the ASGI standard, and it means this list can be passed directly through to the server without the framework doing any extra work. The third element is the body of the response. This looks a bit tricksy, but it\u2019s one of the key concepts in the framework, so we\u2019ll take a little time to understand it. Here\u2019s the actual code for bytes_writer . async def bytes_writer ( buf , chunk_size = - 1 ): if chunk_size == - 1 : yield buf else : start , end = 0 , chunk_size while start < len ( buf ): yield buf [ start : end ] start , end = end , end + chunk_size This is an asynchronous generator . It (optionally) splits the response into chunks which are sent to the client in sequence. We do this for a number of reasons. First it makes the generation of the response asynchronous. Lets say you\u2019re sending an image file. If the file is read asynchronously in chunks the asyncio coroutines will be able to yield during the file chunk reading and when sending the chunk over the network to the client. This means your web server will be able to respond to other requests while the IO is waiting. Second it means the response can be cancelled. If the client browses away from the page before the image has been uploaded, the image data will stop being read and the server will stop sending it. Third we can support streaming content: for example a ticking price or a twitter feed. The last element of the response is a list of push request supported by the HTTP/2 protocol which I won\u2019t discuss that here. Routing \u00b6 In the above example routing was implemented with a decorator: @app . on_http_request ({ 'GET' }, '/hello-world' ) The first argument is a set of HTTP methods that are supported by the handler, and the second is the path to which the handler will respond. I used the decorator routing style for simplicity, however it could have been done in the following manner: import asyncio from hypercorn.asyncio import serve from hypercorn.config import Config from bareasgi import Application , bytes_writer async def http_request_callback ( scope , info , matches , content ): headers = [ ( b 'content-type' , b 'text/plain' ) ] return 200 , headers , bytes_writer ( b 'Hello, World!' ) app = Application () app . http_router . add ({ 'GET' }, '/hello-world' ) config = Config () config . bind = [ \"0.0.0.0:9009\" ] asyncio . run ( serve ( app , config )) This is my preferred method, as it allows more control over the creation of the Application object. In the examples above we used a literal path. We could also have used a parameterised path: '/foo/ {name} /{id:int}/{created:datetime:%Y-%m- %d }' Note how the parameters can optionally have types, and some types can have parse patterns. There is also the special parameter {path} which captures all remaining path elements. The captured parameters are passed into the HTTP request handler as the matches argument which is a dict of the parameter names as keys for the matched values. What next? \u00b6 Either go back to the table of contents or go to the simple rest tutorial.","title":"Getting Started with bareASGI"},{"location":"tutorial/getting-started/#getting-started-with-bareasgi","text":"","title":"Getting Started with bareASGI"},{"location":"tutorial/getting-started/#prerequisites","text":"","title":"Prerequisites"},{"location":"tutorial/getting-started/#asgi-servers","text":"The bareASGI package is a web framework package for ASGI servers, so the first thing required is a server. The servers I have been using are: hypercorn uvicorn At the time of writing hypercorn has the best support for HTTP/2, while uvicorn is the most simple to use. Checkout the links above for installation instructions, The examples will use both servers.","title":"ASGI Servers"},{"location":"tutorial/getting-started/#bareasgi","text":"Finally we must install bareASGI. The bare libraries use poetry , but you can just use pip if you prefer. $ pip install bareasgi","title":"bareASGI"},{"location":"tutorial/getting-started/#visual-studio-code","text":"I use Visual Studio Code as my development environment, and I have left the .vscode files with my settings and launch configurations.","title":"Visual Studio Code"},{"location":"tutorial/getting-started/#hello-world","text":"Here's a simple hello world program with a link to the source code here , and here here with typing. import uvicorn from bareasgi import Application , bytes_writer app = Application () @app . on_http_request ({ 'GET' }, '/' ) async def http_request_handler ( scope , info , matches , content ): return 200 , [( b 'content-type' , b 'text/plain' )], bytes_writer ( b 'Hello, World!' ) uvicorn . run ( app , port = 9009 ) Browsing to http://localhost:9009 will show \"Hello, World!\". Now let\u2019s take this apart.","title":"Hello, World!"},{"location":"tutorial/getting-started/#the-http-request-handler","text":"As it\u2019s name suggests the http_request_handler function handles an HTTP request . It\u2019s arguments form the request, and it returns a response . Unlike other frameworks I chose not to wrap these in an object. There aren\u2019t many, and I took the view that the less work done that isn\u2019t strictly necessary the faster the framework would be. This example doesn\u2019t use any of the input parameters, so I\u2019ll introduce them later, but it does return a whole lot of stuff for the response.","title":"The HTTP Request Handler"},{"location":"tutorial/getting-started/#the-http-response","text":"The first element of the response tuple is the 200 HTTP response code . The second element are the headers. These are optional (we could have passed in None), but we\u2019re returning plain text so I set the content-type accordingly. Note that the headers are a list of tuples of bytes. Also the header name is in lower case. This is all part of the ASGI standard, and it means this list can be passed directly through to the server without the framework doing any extra work. The third element is the body of the response. This looks a bit tricksy, but it\u2019s one of the key concepts in the framework, so we\u2019ll take a little time to understand it. Here\u2019s the actual code for bytes_writer . async def bytes_writer ( buf , chunk_size = - 1 ): if chunk_size == - 1 : yield buf else : start , end = 0 , chunk_size while start < len ( buf ): yield buf [ start : end ] start , end = end , end + chunk_size This is an asynchronous generator . It (optionally) splits the response into chunks which are sent to the client in sequence. We do this for a number of reasons. First it makes the generation of the response asynchronous. Lets say you\u2019re sending an image file. If the file is read asynchronously in chunks the asyncio coroutines will be able to yield during the file chunk reading and when sending the chunk over the network to the client. This means your web server will be able to respond to other requests while the IO is waiting. Second it means the response can be cancelled. If the client browses away from the page before the image has been uploaded, the image data will stop being read and the server will stop sending it. Third we can support streaming content: for example a ticking price or a twitter feed. The last element of the response is a list of push request supported by the HTTP/2 protocol which I won\u2019t discuss that here.","title":"The HTTP Response"},{"location":"tutorial/getting-started/#routing","text":"In the above example routing was implemented with a decorator: @app . on_http_request ({ 'GET' }, '/hello-world' ) The first argument is a set of HTTP methods that are supported by the handler, and the second is the path to which the handler will respond. I used the decorator routing style for simplicity, however it could have been done in the following manner: import asyncio from hypercorn.asyncio import serve from hypercorn.config import Config from bareasgi import Application , bytes_writer async def http_request_callback ( scope , info , matches , content ): headers = [ ( b 'content-type' , b 'text/plain' ) ] return 200 , headers , bytes_writer ( b 'Hello, World!' ) app = Application () app . http_router . add ({ 'GET' }, '/hello-world' ) config = Config () config . bind = [ \"0.0.0.0:9009\" ] asyncio . run ( serve ( app , config )) This is my preferred method, as it allows more control over the creation of the Application object. In the examples above we used a literal path. We could also have used a parameterised path: '/foo/ {name} /{id:int}/{created:datetime:%Y-%m- %d }' Note how the parameters can optionally have types, and some types can have parse patterns. There is also the special parameter {path} which captures all remaining path elements. The captured parameters are passed into the HTTP request handler as the matches argument which is a dict of the parameter names as keys for the matched values.","title":"Routing"},{"location":"tutorial/getting-started/#what-next","text":"Either go back to the table of contents or go to the simple rest tutorial.","title":"What next?"},{"location":"tutorial/headers/","text":"Headers (including cookies) \u00b6 As you might expect, the support for sending and receiving headers is pretty bare! The ASGI servers send and receive headers as a list of 2-tuples of bytes, e.g. headers = [ ( b 'content-type' : b 'application/json' ), ( b 'set-cookie' , b 'first=first cookie' ) ] Most templates preprocess these to dict fo lists of strings. However, I found that in many cases I never even need to look at the headers, so it seemed like an unnecessary overhead. The approach taken by this framework is to provide some utility functions. bareUtils \u00b6 The bareASGI package includes bareUtils as a dependency. Amongst other things this provides utilities for headers. These are all pretty basic and I encourage you to build your own. The module I use the most is bareUtils.header . import bareUtils.header as header accept = header . find ( b 'accept' , scope [ 'headers' ]) content_type = header . find ( b 'content-type' , scope [ 'headers' ], b 'application/json' ) cookies = header . find_all ( b 'cookie' , scope [ 'headers' ]) In the above example the accept header would be searched for, or None if not present. With the find function, the first matching entry is returned. For content-type a default of b'application/json' is provided. In the last example all headers of name cookie are returned in a list. As you can see, no attempt is made to process the headers into dictionaries or strings. Header Helpers \u00b6 There are a number of helper methods written for the more common headers. For example to retrieve the content-type the following function can be used. >>> import bareutils.header as header >>> header . content_type ([( b 'content-type' , b 'text/html; charset=UTF-8' )]) ( b 'text/html' , { b 'charset' : b 'UTF-8' }) Cookies \u00b6 The source code for the following example can be found here (and here here with typing). The key part of the code is where we set the cookies. async def post_form ( scope , info , matches , content ): content_type = header . find ( b 'content-type' , scope [ 'headers' ]) if content_type != b 'application/x-www-form-urlencoded' : return 500 variables = await text_reader ( content ) values = dict ( parse_qsl ( variables )) first_name = values [ 'first_name' ] last_name = values [ 'last_name' ] headers = [ ( b 'location' , b '/get_form' ), ( b 'set-cookie' , f 'first_name= { first_name } ' . encode ()), ( b 'set-cookie' , f 'last_name= { last_name } ' . encode ()), ] return 303 , headers This handler receives the POST from the form. First it checks that the content type is appropriate for form data. Then it reads the body and unpacks it. Note that there is no special support for unpacking, we simply use the urllib.parse.parse_sql function from the standard library. Finally it sets the cookies with set-cookie in the headers. The bareUtils package provides a utility function encode_set_cookie which we could have used, but in this case it was unnecessary. Here is the prototype for encode_set_cookie . def encode_set_cookie ( name : bytes , value : bytes , * , expires : Optional [ datetime ] = None , max_age : Optional [ Union [ int , timedelta ]] = None , path : Optional [ bytes ] = None , domain : Optional [ bytes ] = None , secure : bool = False , http_only : bool = False , same_site : Optional [ bool ] = None ) -> bytes : ... There is a complimentary decode function. def decode_set_cookie ( set_cookie : bytes ) -> Mapping [ str , Any ]: The form handler which presents the form looks like this: async def get_form ( scope , info , matches , content ): cookies = header . cookie ( scope [ 'headers' ]) first_name = cookies . get ( b 'first_name' , [ b 'Micky' ])[ 0 ] last_name = cookies . get ( b 'last_name' , [ b 'Mouse' ])[ 0 ] html_list = '<dl>' for name , values in cookies . items (): for value in values : html_list += f '<dt> { name . decode () } </dt><dd> { value . decode () } </dd>' html_list += '</dl>' html = FORM_HTML . format ( first_name = first_name . decode (), last_name = last_name . decode (), cookies = html_list ) headers = [ ( b 'content-type' , b 'text/html' ), ] return 200 , headers , text_writer ( html ) It uses another utility function header.cookies which simply packs the cookies into a dict. Note that multiple cookies of the same name may be passed. What next? \u00b6 Either go back to the table of contents or go to the cors tutorial.","title":"Headers (including cookies)"},{"location":"tutorial/headers/#headers-including-cookies","text":"As you might expect, the support for sending and receiving headers is pretty bare! The ASGI servers send and receive headers as a list of 2-tuples of bytes, e.g. headers = [ ( b 'content-type' : b 'application/json' ), ( b 'set-cookie' , b 'first=first cookie' ) ] Most templates preprocess these to dict fo lists of strings. However, I found that in many cases I never even need to look at the headers, so it seemed like an unnecessary overhead. The approach taken by this framework is to provide some utility functions.","title":"Headers (including cookies)"},{"location":"tutorial/headers/#bareutils","text":"The bareASGI package includes bareUtils as a dependency. Amongst other things this provides utilities for headers. These are all pretty basic and I encourage you to build your own. The module I use the most is bareUtils.header . import bareUtils.header as header accept = header . find ( b 'accept' , scope [ 'headers' ]) content_type = header . find ( b 'content-type' , scope [ 'headers' ], b 'application/json' ) cookies = header . find_all ( b 'cookie' , scope [ 'headers' ]) In the above example the accept header would be searched for, or None if not present. With the find function, the first matching entry is returned. For content-type a default of b'application/json' is provided. In the last example all headers of name cookie are returned in a list. As you can see, no attempt is made to process the headers into dictionaries or strings.","title":"bareUtils"},{"location":"tutorial/headers/#header-helpers","text":"There are a number of helper methods written for the more common headers. For example to retrieve the content-type the following function can be used. >>> import bareutils.header as header >>> header . content_type ([( b 'content-type' , b 'text/html; charset=UTF-8' )]) ( b 'text/html' , { b 'charset' : b 'UTF-8' })","title":"Header Helpers"},{"location":"tutorial/headers/#cookies","text":"The source code for the following example can be found here (and here here with typing). The key part of the code is where we set the cookies. async def post_form ( scope , info , matches , content ): content_type = header . find ( b 'content-type' , scope [ 'headers' ]) if content_type != b 'application/x-www-form-urlencoded' : return 500 variables = await text_reader ( content ) values = dict ( parse_qsl ( variables )) first_name = values [ 'first_name' ] last_name = values [ 'last_name' ] headers = [ ( b 'location' , b '/get_form' ), ( b 'set-cookie' , f 'first_name= { first_name } ' . encode ()), ( b 'set-cookie' , f 'last_name= { last_name } ' . encode ()), ] return 303 , headers This handler receives the POST from the form. First it checks that the content type is appropriate for form data. Then it reads the body and unpacks it. Note that there is no special support for unpacking, we simply use the urllib.parse.parse_sql function from the standard library. Finally it sets the cookies with set-cookie in the headers. The bareUtils package provides a utility function encode_set_cookie which we could have used, but in this case it was unnecessary. Here is the prototype for encode_set_cookie . def encode_set_cookie ( name : bytes , value : bytes , * , expires : Optional [ datetime ] = None , max_age : Optional [ Union [ int , timedelta ]] = None , path : Optional [ bytes ] = None , domain : Optional [ bytes ] = None , secure : bool = False , http_only : bool = False , same_site : Optional [ bool ] = None ) -> bytes : ... There is a complimentary decode function. def decode_set_cookie ( set_cookie : bytes ) -> Mapping [ str , Any ]: The form handler which presents the form looks like this: async def get_form ( scope , info , matches , content ): cookies = header . cookie ( scope [ 'headers' ]) first_name = cookies . get ( b 'first_name' , [ b 'Micky' ])[ 0 ] last_name = cookies . get ( b 'last_name' , [ b 'Mouse' ])[ 0 ] html_list = '<dl>' for name , values in cookies . items (): for value in values : html_list += f '<dt> { name . decode () } </dt><dd> { value . decode () } </dd>' html_list += '</dl>' html = FORM_HTML . format ( first_name = first_name . decode (), last_name = last_name . decode (), cookies = html_list ) headers = [ ( b 'content-type' , b 'text/html' ), ] return 200 , headers , text_writer ( html ) It uses another utility function header.cookies which simply packs the cookies into a dict. Note that multiple cookies of the same name may be passed.","title":"Cookies"},{"location":"tutorial/headers/#what-next","text":"Either go back to the table of contents or go to the cors tutorial.","title":"What next?"},{"location":"tutorial/https/","text":"HTTPS \u00b6 While using https is not strictly a feature of this web framework, it's a common requirement for two main reasons: for secure communication, and for enabling HTTP/2. HTTP/2 \u00b6 The HTTP/2 protocol is now supported by all modern browsers, and removes a number of significant performance problems. While not intrinsically necessary, it is typically only used by browsers over an https connection. Certificates \u00b6 There is a great deal of information on generating certificates online. I have my own project which generates the certificates with a makefile . The following examples require a certificate in $HOME/.keys/server.crt and a key in $HOME/.keys/server.key . Uvicorn \u00b6 The code required for uvicorn is as follows. app = Application () app . http_router . add ({ 'GET' }, '/' , test_page ) uvicorn . run ( app , host = '0.0.0.0' , port = 9009 , ssl_certfile = os . path . expanduser ( f \"~/.keys/server.crt\" ), ssl_keyfile = os . path . expanduser ( f \"~/.keys/server.key\" ) ) The full source code for the example can be found here . Hypercorn \u00b6 The code required for hypercorn is as follows: app = Application () app . http_router . add ({ 'GET' }, '/' , test_page ) loop = asyncio . new_event_loop () asyncio . set_event_loop ( loop ) shutdown_event = asyncio . Event () def _signal_handler ( * _ : Any ) -> None : shutdown_event . set () loop . add_signal_handler ( signal . SIGTERM , _signal_handler ) loop . add_signal_handler ( signal . SIGINT , _signal_handler ) config = Config () config . bind = [ \"0.0.0.0:9009\" ] config . loglevel = 'debug' config . certfile = os . path . expanduser ( f \"~/.keys/server.crt\" ) config . keyfile = os . path . expanduser ( f \"~/.keys/server.key\" ) loop . run_until_complete ( serve ( app , config , shutdown_trigger = shutdown_event . wait # type: ignore ) ) The full source code for the example can be found here . What next? \u00b6 Either go back to the table of contents or go to the middleware tutorial.","title":"HTTPS"},{"location":"tutorial/https/#https","text":"While using https is not strictly a feature of this web framework, it's a common requirement for two main reasons: for secure communication, and for enabling HTTP/2.","title":"HTTPS"},{"location":"tutorial/https/#http2","text":"The HTTP/2 protocol is now supported by all modern browsers, and removes a number of significant performance problems. While not intrinsically necessary, it is typically only used by browsers over an https connection.","title":"HTTP/2"},{"location":"tutorial/https/#certificates","text":"There is a great deal of information on generating certificates online. I have my own project which generates the certificates with a makefile . The following examples require a certificate in $HOME/.keys/server.crt and a key in $HOME/.keys/server.key .","title":"Certificates"},{"location":"tutorial/https/#uvicorn","text":"The code required for uvicorn is as follows. app = Application () app . http_router . add ({ 'GET' }, '/' , test_page ) uvicorn . run ( app , host = '0.0.0.0' , port = 9009 , ssl_certfile = os . path . expanduser ( f \"~/.keys/server.crt\" ), ssl_keyfile = os . path . expanduser ( f \"~/.keys/server.key\" ) ) The full source code for the example can be found here .","title":"Uvicorn"},{"location":"tutorial/https/#hypercorn","text":"The code required for hypercorn is as follows: app = Application () app . http_router . add ({ 'GET' }, '/' , test_page ) loop = asyncio . new_event_loop () asyncio . set_event_loop ( loop ) shutdown_event = asyncio . Event () def _signal_handler ( * _ : Any ) -> None : shutdown_event . set () loop . add_signal_handler ( signal . SIGTERM , _signal_handler ) loop . add_signal_handler ( signal . SIGINT , _signal_handler ) config = Config () config . bind = [ \"0.0.0.0:9009\" ] config . loglevel = 'debug' config . certfile = os . path . expanduser ( f \"~/.keys/server.crt\" ) config . keyfile = os . path . expanduser ( f \"~/.keys/server.key\" ) loop . run_until_complete ( serve ( app , config , shutdown_trigger = shutdown_event . wait # type: ignore ) ) The full source code for the example can be found here .","title":"Hypercorn"},{"location":"tutorial/https/#what-next","text":"Either go back to the table of contents or go to the middleware tutorial.","title":"What next?"},{"location":"tutorial/jinja2/","text":"Jinja2 Templating \u00b6 The package that provides jinja2 support is bareASGI-jinja2 . Installation \u00b6 The package can be installed as follows. pip install bareasgi-jinja2 Usage \u00b6 A helper method can be used to add the support. Assuming the templates are in a folder named templates : from bareasgi import Application , import bareasgi_jinja2 import jinja2 import pkg_resources app = Application ( info = dict ( config = config )) templates = pkg_resources . resource_filename ( __name__ , \"templates\" ) env = jinja2 . Environment ( loader = jinja2 . FileSystemLoader ( templates ), autoescape = jinja2 . select_autoescape ([ 'html' , 'xml' ]), enable_async = True ) bareasgi_jinja2 . add_jinja2 ( app , env ) A decorator is applied to request handlers which use a jinja2 template. import bareasgi_jinja2 @bareasgi_jinja2 . template ( 'index.html' ) async def handle_index_request ( scope , info , matches , content ): return { 'title' : 'bareASGI' } The decorator specifies the template to be used. The request handler returns a dict the values of which are available in the template.","title":"Jinja2 Templating"},{"location":"tutorial/jinja2/#jinja2-templating","text":"The package that provides jinja2 support is bareASGI-jinja2 .","title":"Jinja2 Templating"},{"location":"tutorial/jinja2/#installation","text":"The package can be installed as follows. pip install bareasgi-jinja2","title":"Installation"},{"location":"tutorial/jinja2/#usage","text":"A helper method can be used to add the support. Assuming the templates are in a folder named templates : from bareasgi import Application , import bareasgi_jinja2 import jinja2 import pkg_resources app = Application ( info = dict ( config = config )) templates = pkg_resources . resource_filename ( __name__ , \"templates\" ) env = jinja2 . Environment ( loader = jinja2 . FileSystemLoader ( templates ), autoescape = jinja2 . select_autoescape ([ 'html' , 'xml' ]), enable_async = True ) bareasgi_jinja2 . add_jinja2 ( app , env ) A decorator is applied to request handlers which use a jinja2 template. import bareasgi_jinja2 @bareasgi_jinja2 . template ( 'index.html' ) async def handle_index_request ( scope , info , matches , content ): return { 'title' : 'bareASGI' } The decorator specifies the template to be used. The request handler returns a dict the values of which are available in the template.","title":"Usage"},{"location":"tutorial/lifespan/","text":"Lifespan \u00b6 Lifespan events occur when the server starts up and shuts down. On startup they can be used for initialization, or for starting long running tasks. On shutdown they can clean up resources and provide graceful termination. You can find the ASGI documentation here . The source code for the following example can be found here (and here here with typing). Handlers \u00b6 The following code creates an application with a startup and shutdown handler. The handlers simply log a message. import asyncio import logging import uvicorn from bareasgi import Application , text_writer async def on_startup ( scope , info , request ): print ( \"Running startup handler\" ) async def on_shutdown ( scope , info , request ): print ( \"Running shutdown handler\" ) app = Application ( startup_handlers = [ on_startup ], shutdown_handlers = [ on_shutdown ] ) uvicorn . run ( app , port = 9009 ) We can add the handlers at any point before the application starts (or stops for shutdown handlers). app = Application () app . startup_handlers . append ( on_startup ) app . shutdown_handlers . append ( on_shutdown ) We could have used a decorator instead. app = Application () @app . on_startup async def on_startup ( scope , info , request ): print ( \"Running startup handler\" ) Handler Parameters \u00b6 Scope \u00b6 The scope parameter contains the unmodified ASGI scope defined here . It doesn't contain much that's useful, but I pass it for completeness. Info \u00b6 The info parameter contains the data that is shared across the application. This is typically used to retrieve configuration, and store resources. Request \u00b6 The request is another unmodified piece of ASGI data, which contains the content of the startup or shutdown event. This is also not particularly useful, and is provided for completeness What next? \u00b6 Either go back to the table of contents or go to the background tasks tutorial.","title":"Lifespan"},{"location":"tutorial/lifespan/#lifespan","text":"Lifespan events occur when the server starts up and shuts down. On startup they can be used for initialization, or for starting long running tasks. On shutdown they can clean up resources and provide graceful termination. You can find the ASGI documentation here . The source code for the following example can be found here (and here here with typing).","title":"Lifespan"},{"location":"tutorial/lifespan/#handlers","text":"The following code creates an application with a startup and shutdown handler. The handlers simply log a message. import asyncio import logging import uvicorn from bareasgi import Application , text_writer async def on_startup ( scope , info , request ): print ( \"Running startup handler\" ) async def on_shutdown ( scope , info , request ): print ( \"Running shutdown handler\" ) app = Application ( startup_handlers = [ on_startup ], shutdown_handlers = [ on_shutdown ] ) uvicorn . run ( app , port = 9009 ) We can add the handlers at any point before the application starts (or stops for shutdown handlers). app = Application () app . startup_handlers . append ( on_startup ) app . shutdown_handlers . append ( on_shutdown ) We could have used a decorator instead. app = Application () @app . on_startup async def on_startup ( scope , info , request ): print ( \"Running startup handler\" )","title":"Handlers"},{"location":"tutorial/lifespan/#handler-parameters","text":"","title":"Handler Parameters"},{"location":"tutorial/lifespan/#scope","text":"The scope parameter contains the unmodified ASGI scope defined here . It doesn't contain much that's useful, but I pass it for completeness.","title":"Scope"},{"location":"tutorial/lifespan/#info","text":"The info parameter contains the data that is shared across the application. This is typically used to retrieve configuration, and store resources.","title":"Info"},{"location":"tutorial/lifespan/#request","text":"The request is another unmodified piece of ASGI data, which contains the content of the startup or shutdown event. This is also not particularly useful, and is provided for completeness","title":"Request"},{"location":"tutorial/lifespan/#what-next","text":"Either go back to the table of contents or go to the background tasks tutorial.","title":"What next?"},{"location":"tutorial/middleware/","text":"Middleware \u00b6 Middleware provides a means of applying common tasks to a request without having to repeat the code. For example one wanted to compress the output of request handlers, one might add such middleware that would take the output of a request handler and compress it. Another example would be authentication, The middleware could check if a user had logged in before allowing the request handler to be called. Global middleware \u00b6 The following example creates a chain of two middleware functions which add content to a \"message\" provided by the info parameter. The source code for the following example can be found here (and here here with typing). import uvicorn from bareasgi import Application , text_writer async def first_middleware ( scope , info , matches , content , handler ): print ( \"First middleware - entry\" ) info [ 'message' ] = 'This is first the middleware. ' status , headers , response , pushes = await handler ( scope , info , matches , content ) print ( \"First middleware - exit\" ) return status , headers , response , pushes async def second_middleware ( scope , info , matches , content , handler ): print ( \"Second middleware - entry\" ) info [ 'message' ] += 'This is the second middleware.' response = await handler ( scope , info , matches , content ) print ( \"Second middleware - exit\" ) return response async def http_request_callback ( scope , info , matches , content ): return 200 , [( b 'content-type' , b 'text/plain' )], text_writer ( info [ 'message' ]) app = Application ( middlewares = [ first_middleware , second_middleware ] ) app . http_router . add ( { 'GET' , 'POST' , 'PUT' , 'DELETE' }, '/' , http_request_callback ) uvicorn . run ( app , port = 9009 ) The point at which the middleware is applied is on the application. app = Application ( middlewares = [ first_middleware , second_middleware ] ) If we look at the first middleware function we can see it takes one more argument, the handler , than a request handler. async def first_middleware ( scope , info , matches , content , handler ): print ( \"First middleware - entry\" ) info [ 'message' ] = 'This is first the middleware. ' status , headers , response , pushes = await handler ( scope , info , matches , content ) print ( \"First middleware - exit\" ) return status , headers , response , pushes The handler is the next function to call. We can see with the two print statement that the middleware completely wraps the subsequent handler. This gives us control of both the inputs and the outputs. Inspecting the output of the program we can see the following results when we browse to the page. First middleware - entry Second middleware - entry Second middleware - exit First middleware - exit Route local middleware \u00b6 We can also apply the middleware to a specific route. For example: from bareasgi.middleware import mw ... app = Application ( info = { 'message' : 'Unmodified' }) app . http_router . add ( { 'GET' , 'POST' , 'PUT' , 'DELETE' }, '/with' , mw ( first_middleware , second_middleware , handler = http_request_callback ) ) app . http_router . add ( { 'GET' , 'POST' , 'PUT' , 'DELETE' }, '/without' , http_request_callback ) Now if we brows to http://localhost:9009/with we can see the middleware being called, but when we browse to http://localhost:9009/without it is not. The source code for this example can be found here (and here here with typing). What next? \u00b6 Either go back to the table of contents or go to the WebSockets tutorial.","title":"Middleware"},{"location":"tutorial/middleware/#middleware","text":"Middleware provides a means of applying common tasks to a request without having to repeat the code. For example one wanted to compress the output of request handlers, one might add such middleware that would take the output of a request handler and compress it. Another example would be authentication, The middleware could check if a user had logged in before allowing the request handler to be called.","title":"Middleware"},{"location":"tutorial/middleware/#global-middleware","text":"The following example creates a chain of two middleware functions which add content to a \"message\" provided by the info parameter. The source code for the following example can be found here (and here here with typing). import uvicorn from bareasgi import Application , text_writer async def first_middleware ( scope , info , matches , content , handler ): print ( \"First middleware - entry\" ) info [ 'message' ] = 'This is first the middleware. ' status , headers , response , pushes = await handler ( scope , info , matches , content ) print ( \"First middleware - exit\" ) return status , headers , response , pushes async def second_middleware ( scope , info , matches , content , handler ): print ( \"Second middleware - entry\" ) info [ 'message' ] += 'This is the second middleware.' response = await handler ( scope , info , matches , content ) print ( \"Second middleware - exit\" ) return response async def http_request_callback ( scope , info , matches , content ): return 200 , [( b 'content-type' , b 'text/plain' )], text_writer ( info [ 'message' ]) app = Application ( middlewares = [ first_middleware , second_middleware ] ) app . http_router . add ( { 'GET' , 'POST' , 'PUT' , 'DELETE' }, '/' , http_request_callback ) uvicorn . run ( app , port = 9009 ) The point at which the middleware is applied is on the application. app = Application ( middlewares = [ first_middleware , second_middleware ] ) If we look at the first middleware function we can see it takes one more argument, the handler , than a request handler. async def first_middleware ( scope , info , matches , content , handler ): print ( \"First middleware - entry\" ) info [ 'message' ] = 'This is first the middleware. ' status , headers , response , pushes = await handler ( scope , info , matches , content ) print ( \"First middleware - exit\" ) return status , headers , response , pushes The handler is the next function to call. We can see with the two print statement that the middleware completely wraps the subsequent handler. This gives us control of both the inputs and the outputs. Inspecting the output of the program we can see the following results when we browse to the page. First middleware - entry Second middleware - entry Second middleware - exit First middleware - exit","title":"Global middleware"},{"location":"tutorial/middleware/#route-local-middleware","text":"We can also apply the middleware to a specific route. For example: from bareasgi.middleware import mw ... app = Application ( info = { 'message' : 'Unmodified' }) app . http_router . add ( { 'GET' , 'POST' , 'PUT' , 'DELETE' }, '/with' , mw ( first_middleware , second_middleware , handler = http_request_callback ) ) app . http_router . add ( { 'GET' , 'POST' , 'PUT' , 'DELETE' }, '/without' , http_request_callback ) Now if we brows to http://localhost:9009/with we can see the middleware being called, but when we browse to http://localhost:9009/without it is not. The source code for this example can be found here (and here here with typing).","title":"Route local middleware"},{"location":"tutorial/middleware/#what-next","text":"Either go back to the table of contents or go to the WebSockets tutorial.","title":"What next?"},{"location":"tutorial/server-sent-events/","text":"Server Sent Events \u00b6 Server sent events provide a streaming connection from the server to the browser. These are often overlooked, as they provide less functionality than WebSockets. However if there is not requirement for two way communication they can be highly efficient, particularly as they work seamlessly with HTTP/2. The source code can be found here for the html , and here for the python , (and here here with typing). The request handler \u00b6 The request handler looks as follows. async def test_events ( scope , info , matches , content ): async def send_events (): is_cancelled = False while not is_cancelled : try : print ( 'Sending event' ) yield f 'data: { datetime . now () } \\n\\n\\n ' . encode ( 'utf-8' ) # Defeat buffering by giving the server a nudge. yield ': \\n\\n\\n ' . encode ( 'utf-8' ) await asyncio . sleep ( 1 ) except asyncio . CancelledError : print ( 'Cancelled' ) is_cancelled = True except : # pylint: disable=bare-except print ( 'Failed' ) headers = [ ( b 'cache-control' , b 'no-cache' ), ( b 'content-type' , b 'text/event-stream' ), ( b 'connection' , b 'keep-alive' ) ] return 200 , headers , send_events () The key to understanding this is the last line: return 200, headers, send_events() . The handler is returning a function which is an asynchronous iterator. If we look at the function itself we can that it yields some text (encoded to bytes), then sleeps for a second before continuing this activity. The content-type of the data is text/event-stream which follows a slightly arcane format that can be found here . Here is the javascript that consumes the data: <!DOCTYPE html> < html > < head > < meta charset = \"utf-8\" > < title > Example </ title > </ head > < body > < h1 > Server Sent Events </ h1 > Time: < snap id = \"time\" ></ span > < script > var eventSource = new EventSource ( \"/events\" ) eventSource . onmessage = function ( event ) { element = document . getElementById ( \"time\" ) element . innerHTML = event . data } </ script > </ body > </ html > What next? \u00b6 Either go back to the table of contents or go to the streaming fetch tutorial.","title":"Server Sent Events"},{"location":"tutorial/server-sent-events/#server-sent-events","text":"Server sent events provide a streaming connection from the server to the browser. These are often overlooked, as they provide less functionality than WebSockets. However if there is not requirement for two way communication they can be highly efficient, particularly as they work seamlessly with HTTP/2. The source code can be found here for the html , and here for the python , (and here here with typing).","title":"Server Sent Events"},{"location":"tutorial/server-sent-events/#the-request-handler","text":"The request handler looks as follows. async def test_events ( scope , info , matches , content ): async def send_events (): is_cancelled = False while not is_cancelled : try : print ( 'Sending event' ) yield f 'data: { datetime . now () } \\n\\n\\n ' . encode ( 'utf-8' ) # Defeat buffering by giving the server a nudge. yield ': \\n\\n\\n ' . encode ( 'utf-8' ) await asyncio . sleep ( 1 ) except asyncio . CancelledError : print ( 'Cancelled' ) is_cancelled = True except : # pylint: disable=bare-except print ( 'Failed' ) headers = [ ( b 'cache-control' , b 'no-cache' ), ( b 'content-type' , b 'text/event-stream' ), ( b 'connection' , b 'keep-alive' ) ] return 200 , headers , send_events () The key to understanding this is the last line: return 200, headers, send_events() . The handler is returning a function which is an asynchronous iterator. If we look at the function itself we can that it yields some text (encoded to bytes), then sleeps for a second before continuing this activity. The content-type of the data is text/event-stream which follows a slightly arcane format that can be found here . Here is the javascript that consumes the data: <!DOCTYPE html> < html > < head > < meta charset = \"utf-8\" > < title > Example </ title > </ head > < body > < h1 > Server Sent Events </ h1 > Time: < snap id = \"time\" ></ span > < script > var eventSource = new EventSource ( \"/events\" ) eventSource . onmessage = function ( event ) { element = document . getElementById ( \"time\" ) element . innerHTML = event . data } </ script > </ body > </ html >","title":"The request handler"},{"location":"tutorial/server-sent-events/#what-next","text":"Either go back to the table of contents or go to the streaming fetch tutorial.","title":"What next?"},{"location":"tutorial/simple-rest/","text":"Simple REST \u00b6 This example sends and receives data using REST. You will need something like postman to try it out. We use hypercorn as the ASGI server. The source code can be found here (and here here with typing). import asyncio import json from hypercorn.asyncio import serve from hypercorn.config import Config from bareasgi import Application , text_reader , text_writer import bareutils.header as header async def get_info ( scope , info , matches , content ): accept = header . find ( b 'accept' , scope [ 'headers' ]) if accept != b 'application/json' : return 500 # Get the info text = json . dumps ( info ) headers = [ ( b 'content-type' , b 'application/json' ) ] return 200 , headers , text_writer ( text ) async def set_info ( scope , info , matches , content ): content_type = header . find ( b 'content-type' , scope [ 'headers' ]) if content_type != b 'application/json' : return 500 text = await text_reader ( content ) data = json . loads ( text ) # Set the info info . update ( data ) return 204 app = Application ( info = { 'name' : 'Michael Caine' }) app . http_router . add ({ 'GET' }, '/info' , get_info ) app . http_router . add ({ 'POST' }, '/info' , set_info ) # Start hypercorn config = Config () config . bind = [ \"0.0.0.0:9009\" ] asyncio . run ( serve ( app , config )) To try this out make a GET request to http://localhost:9009/info with the accept header set to application/json . It should respond with a content-type of application/json and body of {\u201cname\": \u201cMichael Caine\"} . Sending a POST to the same endpoint with the body {\u201cname\": \u201cPeter Sellers\"} and a content-type of application/json should respond with a 204 status code. A subsequent GET should return {\u201cname\": \u201cPeter Sellers\"} . Request Parameters \u00b6 In this example we start to use some of the request parameters. Scope \u00b6 The scope is passed directly from the ASGI server. It is a dictionary of values describing the request. We use it here to inspect the headers. Looking at the ASGI cconnection-scope documentation we can see it contains everything the ASGI server knows about the request, including the scheme, the query string, etc. Info \u00b6 The info is a dict which is supplied to the Application on construction (or automatically generated if not). It is the means of the application sharing data. In this example it is created with a name entry. app = Application ( info = { 'name' : 'Michael Caine' }) The GET handler retrieves the info and returns it as a string. text = json . dumps ( info ) headers = [ ( b 'content-type' , b 'application/json' ) ] return 200 , headers , text_writer ( text ) The POST handler reads the new data from the request body and updates the info with whatever was sent. text = await text_reader ( content ) data = json . loads ( text ) info . update ( data ) A subsequent GET will return the new content of info. Content \u00b6 The content is the complement of the body in the response. It is another asynchronous generator and is used to read the body of the request. The text_reader helper function is used to retrieve the body (note this is awaited). Response \u00b6 The handlers respond with 500 if the request was incorrect. if content_type != b 'application/json' : return 500 We can see that it is not necessary to provide all the elements of the response, where all elements to the right would be None . What next? \u00b6 Either go back to the table of contents or go to the lifespan tutorial.","title":"Simple REST"},{"location":"tutorial/simple-rest/#simple-rest","text":"This example sends and receives data using REST. You will need something like postman to try it out. We use hypercorn as the ASGI server. The source code can be found here (and here here with typing). import asyncio import json from hypercorn.asyncio import serve from hypercorn.config import Config from bareasgi import Application , text_reader , text_writer import bareutils.header as header async def get_info ( scope , info , matches , content ): accept = header . find ( b 'accept' , scope [ 'headers' ]) if accept != b 'application/json' : return 500 # Get the info text = json . dumps ( info ) headers = [ ( b 'content-type' , b 'application/json' ) ] return 200 , headers , text_writer ( text ) async def set_info ( scope , info , matches , content ): content_type = header . find ( b 'content-type' , scope [ 'headers' ]) if content_type != b 'application/json' : return 500 text = await text_reader ( content ) data = json . loads ( text ) # Set the info info . update ( data ) return 204 app = Application ( info = { 'name' : 'Michael Caine' }) app . http_router . add ({ 'GET' }, '/info' , get_info ) app . http_router . add ({ 'POST' }, '/info' , set_info ) # Start hypercorn config = Config () config . bind = [ \"0.0.0.0:9009\" ] asyncio . run ( serve ( app , config )) To try this out make a GET request to http://localhost:9009/info with the accept header set to application/json . It should respond with a content-type of application/json and body of {\u201cname\": \u201cMichael Caine\"} . Sending a POST to the same endpoint with the body {\u201cname\": \u201cPeter Sellers\"} and a content-type of application/json should respond with a 204 status code. A subsequent GET should return {\u201cname\": \u201cPeter Sellers\"} .","title":"Simple REST"},{"location":"tutorial/simple-rest/#request-parameters","text":"In this example we start to use some of the request parameters.","title":"Request Parameters"},{"location":"tutorial/simple-rest/#scope","text":"The scope is passed directly from the ASGI server. It is a dictionary of values describing the request. We use it here to inspect the headers. Looking at the ASGI cconnection-scope documentation we can see it contains everything the ASGI server knows about the request, including the scheme, the query string, etc.","title":"Scope"},{"location":"tutorial/simple-rest/#info","text":"The info is a dict which is supplied to the Application on construction (or automatically generated if not). It is the means of the application sharing data. In this example it is created with a name entry. app = Application ( info = { 'name' : 'Michael Caine' }) The GET handler retrieves the info and returns it as a string. text = json . dumps ( info ) headers = [ ( b 'content-type' , b 'application/json' ) ] return 200 , headers , text_writer ( text ) The POST handler reads the new data from the request body and updates the info with whatever was sent. text = await text_reader ( content ) data = json . loads ( text ) info . update ( data ) A subsequent GET will return the new content of info.","title":"Info"},{"location":"tutorial/simple-rest/#content","text":"The content is the complement of the body in the response. It is another asynchronous generator and is used to read the body of the request. The text_reader helper function is used to retrieve the body (note this is awaited).","title":"Content"},{"location":"tutorial/simple-rest/#response","text":"The handlers respond with 500 if the request was incorrect. if content_type != b 'application/json' : return 500 We can see that it is not necessary to provide all the elements of the response, where all elements to the right would be None .","title":"Response"},{"location":"tutorial/simple-rest/#what-next","text":"Either go back to the table of contents or go to the lifespan tutorial.","title":"What next?"},{"location":"tutorial/static-files/","text":"Static Files \u00b6 The package to handler static files is bareASGI-static . Installation \u00b6 The package can be installed as follows. pip install bareasgi-static Usage \u00b6 Use the helper method to add support. import os.path import uvicorn from bareasgi import Application from bareasgi_static import add_static_file_provider here = os . path . abspath ( os . path . dirname ( __file__ )) app = Application () add_static_file_provider ( app , os . path . join ( here , simple_www )) uvicorn . run ( app , port = 9010 )","title":"Static Files"},{"location":"tutorial/static-files/#static-files","text":"The package to handler static files is bareASGI-static .","title":"Static Files"},{"location":"tutorial/static-files/#installation","text":"The package can be installed as follows. pip install bareasgi-static","title":"Installation"},{"location":"tutorial/static-files/#usage","text":"Use the helper method to add support. import os.path import uvicorn from bareasgi import Application from bareasgi_static import add_static_file_provider here = os . path . abspath ( os . path . dirname ( __file__ )) app = Application () add_static_file_provider ( app , os . path . join ( here , simple_www )) uvicorn . run ( app , port = 9010 )","title":"Usage"},{"location":"tutorial/streaming-fetch/","text":"Streaming Fetch \u00b6 If, when reading the server sent events page, you wondered if there was a more general way of streaming data from a server, you were right. The source code can be found here for the html , and here for the python , (and here here with typing). The request handler \u00b6 The request handler looks very similar to that of server sent events, except there is no need to implement the protocol; just streaming data is fine. async def test_events ( scope , info , matches , content ): body = await text_reader ( content ) data = json . loads ( body ) async def send_events (): is_cancelled = False while not is_cancelled : try : print ( 'Sending event' ) message = { 'type' : 'tick' , 'data' : { 'time' : datetime . now () . isoformat (), 'message' : data [ 'message' ] } } line = json . dumps ( message ) + ' \\n ' yield line . encode ( 'utf-8' ) await asyncio . sleep ( 1 ) except asyncio . CancelledError : print ( 'Cancelled' ) is_cancelled = True headers = [ ( b 'cache-control' , b 'no-cache' ), ( b 'content-type' , b 'application/json' ), ( b 'connection' , b 'keep-alive' ) ] return 200 , headers , send_events () Rather than yielding the event source protocol we simply stream JSON, with each JSON message terminated by a newline. Note that, unlike the event stream, we can receive POST requests which may have a body. This allows passing more complex requests than would be feasible with the event source. The client \u00b6 The client code is significantly more complicated. The core of the client side code is the streaming fetch request: function streamingFetch ( url , message ) { eventTarget = new FetchEventTarget ( url , { method : \"POST\" , headers : new Headers ({ accept : \"application/json\" , \"content-type\" : \"application/json\" , }), mode : \"same-origin\" , body : JSON . stringify ( message ), }); eventTarget . addEventListener ( \"tick\" , event => { const data = JSON . stringify ( event . data ); console . log ( data ); }); } This looks line a standard fetch, but the object created acts like an event target. The code for FetchEventTarget looks as follows: function FetchEventTarget ( input , init ) { const eventTarget = new EventTarget (); const textDecoder = new TextDecoder ( \"utf-8\" ); const jsonDecoder = makeJsonDecoder ( input ); const eventStream = makeWriteableEventStream ( eventTarget ); fetch ( input , init ) . then ( response => { response . body . pipeThrough ( new TextDecoderStream ()) . pipeThrough ( jsonDecoder ) . pipeTo ( eventStream ); }) . catch ( error => { eventTarget . dispatchEvent ( new CustomEvent ( \"error\" , { detail : error })); }); return eventTarget ; } Now we can see the actual fetch call being used, however rather than calling response.text we use the body . The body contains a ReadableStream , and the pipe... methods allow processing of the stream. The TextDecoder is a built in class for transforming the stream for bytes to text. The JSON decoder looks like this: function makeJsonDecoder () { return new TransformStream ({ start ( controller ) { controller . buf = \"\" ; controller . pos = 0 ; }, transform ( chunk , controller ) { controller . buf += chunk ; while ( controller . pos < controller . buf . length ) { if ( controller . buf [ controller . pos ] == \"\\n\" ) { const line = controller . buf . substring ( 0 , controller . pos ); controller . enqueue ( JSON . parse ( line )); controller . buf = controller . buf . substring ( controller . pos + 1 ); controller . pos = 0 ; } else { ++ controller . pos ; } } }, }); } It creates the built in class TransformStream and splits the text supplied by the TextDecoder into lines, then parses them as JSON. The last part of the chain is the writable event stream. function makeWriteableEventStream ( eventTarget ) { return new WritableStream ({ start ( controller ) { eventTarget . dispatchEvent ( new Event ( \"start\" )); }, write ( message , controller ) { eventTarget . dispatchEvent ( new MessageEvent ( message . type , { data : message . data }) ); }, close ( controller ) { eventTarget . dispatchEvent ( new CloseEvent ( \"close\" )); }, abort ( reason ) { eventTarget . dispatchEvent ( new CloseEvent ( \"abort\" , { reason })); }, }); } This is the end of the chain and it uses the built in WriteableStream to turn the incoming JSON into events. What next? \u00b6 Either go back to the table of contents or go to the compression tutorial.","title":"Streaming Fetch"},{"location":"tutorial/streaming-fetch/#streaming-fetch","text":"If, when reading the server sent events page, you wondered if there was a more general way of streaming data from a server, you were right. The source code can be found here for the html , and here for the python , (and here here with typing).","title":"Streaming Fetch"},{"location":"tutorial/streaming-fetch/#the-request-handler","text":"The request handler looks very similar to that of server sent events, except there is no need to implement the protocol; just streaming data is fine. async def test_events ( scope , info , matches , content ): body = await text_reader ( content ) data = json . loads ( body ) async def send_events (): is_cancelled = False while not is_cancelled : try : print ( 'Sending event' ) message = { 'type' : 'tick' , 'data' : { 'time' : datetime . now () . isoformat (), 'message' : data [ 'message' ] } } line = json . dumps ( message ) + ' \\n ' yield line . encode ( 'utf-8' ) await asyncio . sleep ( 1 ) except asyncio . CancelledError : print ( 'Cancelled' ) is_cancelled = True headers = [ ( b 'cache-control' , b 'no-cache' ), ( b 'content-type' , b 'application/json' ), ( b 'connection' , b 'keep-alive' ) ] return 200 , headers , send_events () Rather than yielding the event source protocol we simply stream JSON, with each JSON message terminated by a newline. Note that, unlike the event stream, we can receive POST requests which may have a body. This allows passing more complex requests than would be feasible with the event source.","title":"The request handler"},{"location":"tutorial/streaming-fetch/#the-client","text":"The client code is significantly more complicated. The core of the client side code is the streaming fetch request: function streamingFetch ( url , message ) { eventTarget = new FetchEventTarget ( url , { method : \"POST\" , headers : new Headers ({ accept : \"application/json\" , \"content-type\" : \"application/json\" , }), mode : \"same-origin\" , body : JSON . stringify ( message ), }); eventTarget . addEventListener ( \"tick\" , event => { const data = JSON . stringify ( event . data ); console . log ( data ); }); } This looks line a standard fetch, but the object created acts like an event target. The code for FetchEventTarget looks as follows: function FetchEventTarget ( input , init ) { const eventTarget = new EventTarget (); const textDecoder = new TextDecoder ( \"utf-8\" ); const jsonDecoder = makeJsonDecoder ( input ); const eventStream = makeWriteableEventStream ( eventTarget ); fetch ( input , init ) . then ( response => { response . body . pipeThrough ( new TextDecoderStream ()) . pipeThrough ( jsonDecoder ) . pipeTo ( eventStream ); }) . catch ( error => { eventTarget . dispatchEvent ( new CustomEvent ( \"error\" , { detail : error })); }); return eventTarget ; } Now we can see the actual fetch call being used, however rather than calling response.text we use the body . The body contains a ReadableStream , and the pipe... methods allow processing of the stream. The TextDecoder is a built in class for transforming the stream for bytes to text. The JSON decoder looks like this: function makeJsonDecoder () { return new TransformStream ({ start ( controller ) { controller . buf = \"\" ; controller . pos = 0 ; }, transform ( chunk , controller ) { controller . buf += chunk ; while ( controller . pos < controller . buf . length ) { if ( controller . buf [ controller . pos ] == \"\\n\" ) { const line = controller . buf . substring ( 0 , controller . pos ); controller . enqueue ( JSON . parse ( line )); controller . buf = controller . buf . substring ( controller . pos + 1 ); controller . pos = 0 ; } else { ++ controller . pos ; } } }, }); } It creates the built in class TransformStream and splits the text supplied by the TextDecoder into lines, then parses them as JSON. The last part of the chain is the writable event stream. function makeWriteableEventStream ( eventTarget ) { return new WritableStream ({ start ( controller ) { eventTarget . dispatchEvent ( new Event ( \"start\" )); }, write ( message , controller ) { eventTarget . dispatchEvent ( new MessageEvent ( message . type , { data : message . data }) ); }, close ( controller ) { eventTarget . dispatchEvent ( new CloseEvent ( \"close\" )); }, abort ( reason ) { eventTarget . dispatchEvent ( new CloseEvent ( \"abort\" , { reason })); }, }); } This is the end of the chain and it uses the built in WriteableStream to turn the incoming JSON into events.","title":"The client"},{"location":"tutorial/streaming-fetch/#what-next","text":"Either go back to the table of contents or go to the compression tutorial.","title":"What next?"},{"location":"tutorial/websockets/","text":"Web Sockets \u00b6 The bareASGI framework has full support for WebSockets . You can find the ASGI documentation here . The source code for the following example can be found here (and here here with typing). The WebSocket Handler \u00b6 The WebSocket request handler has a different prototype than the http request handler. Here's the handler from our example program. async def websocket_handler ( scope : Scope , info : Info , matches : RouteMatches , web_socket : WebSocket ) -> None : \"\"\"The websocket callback handler\"\"\" await web_socket . accept () try : while True : text = await web_socket . receive () if text is None : break await web_socket . send ( 'You said: ' + text ) except Exception as error : print ( error ) await web_socket . close () As you can see the difference is the last parameter, the web_socket itself. The first thing we need to do is accept the connection (assuming we want to). Then we wait for a message to be sent from the client, text = await web_socket.receive() , then send it back, await web_socket.send('You said: ' + text) . API \u00b6 The web_socket is an object with the following prototype: class WebSocket : async def accept ( self , subprotocol : Optional [ str ] = None , headers : Optional [ List [ Headers ]] = None ) -> None : \"\"\"Accept the socket. This must be done before any other action is taken. :param subprotocol: An optional subprotocol sent by the client. :param headers: Optional headers sent by the client. \"\"\" async def receive ( self ) -> Optional [ Union [ bytes , str ]]: \"\"\"Receive data from the WebSocket. :return: Either bytes of a string depending on the client. \"\"\" async def send ( self , content : Union [ bytes , str ]) -> None : \"\"\"Send data to the client. :param content: Either bytes or a string. \"\"\" async def close ( self , code : int = 1000 ) -> None : \"\"\"Closes the WebSocket. :param code: The reason code (defaults to 1000). \"\"\" @property def code ( self ) -> Optional [ int ]: \"\"\"The close code :return: The code returned when the WebSocket was closed otherwise None :rtype: Optional[int] \"\"\" HTTP/2 and haproxy \u00b6 There are some interesting issues around using HTTP/2 for WebSockets. At the time of writing FireFox is the only browser that supports HTTP/2 and WebSockets. Other browsers will downgrade the connection to HTTP/1.1. This means that non-FireFox browsers with create a new connection for the WebSocket, rather than use the existing connection as they would for an HTTP/2 session. If the web server sits behind a proxy server (specifically haproxy), the proxy server will only negotiate the protocol on the initial connect. This leads to the subsequent downgrade being discarded, and the WebSocket connection fails. If you have this setup, unless you can guarantee all your clients use FireFox, you will have to clamp your haproxy to HTTP/1.1. If you don't require the two way facility that WebSockets offer you can use server sent events or a streaming. What next? \u00b6 Either go back to the table of contents or go to the headers (including cookies) tutorial.","title":"Web Sockets"},{"location":"tutorial/websockets/#web-sockets","text":"The bareASGI framework has full support for WebSockets . You can find the ASGI documentation here . The source code for the following example can be found here (and here here with typing).","title":"Web Sockets"},{"location":"tutorial/websockets/#the-websocket-handler","text":"The WebSocket request handler has a different prototype than the http request handler. Here's the handler from our example program. async def websocket_handler ( scope : Scope , info : Info , matches : RouteMatches , web_socket : WebSocket ) -> None : \"\"\"The websocket callback handler\"\"\" await web_socket . accept () try : while True : text = await web_socket . receive () if text is None : break await web_socket . send ( 'You said: ' + text ) except Exception as error : print ( error ) await web_socket . close () As you can see the difference is the last parameter, the web_socket itself. The first thing we need to do is accept the connection (assuming we want to). Then we wait for a message to be sent from the client, text = await web_socket.receive() , then send it back, await web_socket.send('You said: ' + text) .","title":"The WebSocket Handler"},{"location":"tutorial/websockets/#api","text":"The web_socket is an object with the following prototype: class WebSocket : async def accept ( self , subprotocol : Optional [ str ] = None , headers : Optional [ List [ Headers ]] = None ) -> None : \"\"\"Accept the socket. This must be done before any other action is taken. :param subprotocol: An optional subprotocol sent by the client. :param headers: Optional headers sent by the client. \"\"\" async def receive ( self ) -> Optional [ Union [ bytes , str ]]: \"\"\"Receive data from the WebSocket. :return: Either bytes of a string depending on the client. \"\"\" async def send ( self , content : Union [ bytes , str ]) -> None : \"\"\"Send data to the client. :param content: Either bytes or a string. \"\"\" async def close ( self , code : int = 1000 ) -> None : \"\"\"Closes the WebSocket. :param code: The reason code (defaults to 1000). \"\"\" @property def code ( self ) -> Optional [ int ]: \"\"\"The close code :return: The code returned when the WebSocket was closed otherwise None :rtype: Optional[int] \"\"\"","title":"API"},{"location":"tutorial/websockets/#http2-and-haproxy","text":"There are some interesting issues around using HTTP/2 for WebSockets. At the time of writing FireFox is the only browser that supports HTTP/2 and WebSockets. Other browsers will downgrade the connection to HTTP/1.1. This means that non-FireFox browsers with create a new connection for the WebSocket, rather than use the existing connection as they would for an HTTP/2 session. If the web server sits behind a proxy server (specifically haproxy), the proxy server will only negotiate the protocol on the initial connect. This leads to the subsequent downgrade being discarded, and the WebSocket connection fails. If you have this setup, unless you can guarantee all your clients use FireFox, you will have to clamp your haproxy to HTTP/1.1. If you don't require the two way facility that WebSockets offer you can use server sent events or a streaming.","title":"HTTP/2 and haproxy"},{"location":"tutorial/websockets/#what-next","text":"Either go back to the table of contents or go to the headers (including cookies) tutorial.","title":"What next?"},{"location":"user-guide/application/","text":"Application \u00b6 The application class has the following constructor: Application ( middlewares : Optional [ List [ HttpMiddlewareCallback ]], http_router : Optional [ HttpRouter ], web_socket_router : Optional [ WebSocketRouter ], startup_handlers : Optional [ List [ StartupHandler ]], shutdown_handlers : Optional [ List [ ShutdownHandler ]], not_found_response : Optional [ HttpResponse ], info : Optional [ MutableMapping [ str , Any ]] ) All arguments are optional. The info argument provides a place for application specific data. The application provides some properties that can be used for configuration: Application . info -> MutableMapping [ str , Any ] Application . middlewares -> List [] Application . http_router -> HttpRouter Application . ws_router -> WebSocketRouter Application . startup_handlers -> List [ StartupHandler ] Application . shutdown_handlers -> List [ ShutdownHandler ]","title":"Application"},{"location":"user-guide/application/#application","text":"The application class has the following constructor: Application ( middlewares : Optional [ List [ HttpMiddlewareCallback ]], http_router : Optional [ HttpRouter ], web_socket_router : Optional [ WebSocketRouter ], startup_handlers : Optional [ List [ StartupHandler ]], shutdown_handlers : Optional [ List [ ShutdownHandler ]], not_found_response : Optional [ HttpResponse ], info : Optional [ MutableMapping [ str , Any ]] ) All arguments are optional. The info argument provides a place for application specific data. The application provides some properties that can be used for configuration: Application . info -> MutableMapping [ str , Any ] Application . middlewares -> List [] Application . http_router -> HttpRouter Application . ws_router -> WebSocketRouter Application . startup_handlers -> List [ StartupHandler ] Application . shutdown_handlers -> List [ ShutdownHandler ]","title":"Application"},{"location":"user-guide/asgi/","text":"ASGI \u00b6 What is ASGI? \u00b6 An ASGI server sits at the front of a web application receiving and sending HTTP and WebSocket messages. The client code simply sends and receives dictionaries which describe the HTTP messages. At it's heart ASGI is a specification. You can find the ASGI specification here . Why? \u00b6 Back in the days of Python 2 where there was no async/await functionality, a lot of effort was required to make a responsive web server in python. Essentially it was necessary to have a separate service which would create a new process to service the request. Out of this emerged the WSGI specification, and Python applications which conformed to the specification could choose from a selection of servers which supported the spec. The ASGI specification is an asynchronous version of WSGI, which supports the async/await functionlity of Python 3. This allows us to write a responsive web service without the necessity of creating multiple processes, although this may still be desirable for more performance. Servers \u00b6 A number of servers have been written that support the specification. I have been using: uvicorn hypercorn","title":"ASGI"},{"location":"user-guide/asgi/#asgi","text":"","title":"ASGI"},{"location":"user-guide/asgi/#what-is-asgi","text":"An ASGI server sits at the front of a web application receiving and sending HTTP and WebSocket messages. The client code simply sends and receives dictionaries which describe the HTTP messages. At it's heart ASGI is a specification. You can find the ASGI specification here .","title":"What is ASGI?"},{"location":"user-guide/asgi/#why","text":"Back in the days of Python 2 where there was no async/await functionality, a lot of effort was required to make a responsive web server in python. Essentially it was necessary to have a separate service which would create a new process to service the request. Out of this emerged the WSGI specification, and Python applications which conformed to the specification could choose from a selection of servers which supported the spec. The ASGI specification is an asynchronous version of WSGI, which supports the async/await functionlity of Python 3. This allows us to write a responsive web service without the necessity of creating multiple processes, although this may still be desirable for more performance.","title":"Why?"},{"location":"user-guide/asgi/#servers","text":"A number of servers have been written that support the specification. I have been using: uvicorn hypercorn","title":"Servers"},{"location":"user-guide/background-tasks/","text":"Background Tasks \u00b6 It is a common requirement to run background tasks while the server is processing requests. For example incoming data might have to be processed before being used in subsequent responses. An important implementation details is that any code which uses the asyncio event loop (e.g. asyncio.Event(), asyncio.Queue(), etc.) must be done in the context of the ASGI server. Failure to do this will lead to errors complaining that the object is owned by a different event loop. This can be achieved by passing the application startup and shutdown handlers: async def my_startup_handler ( scope : Scope , info : Info , request : Message ) -> None : ... async def my_shutdown_handler ( scope : Scope , info : Info , request : Message ) -> None : ... # Create the application with startup and shutdown handlers. app = Application ( startup_handlers = [ my_startup_handler ], shutdown_handlers = [ my_shutdown_handler ] ) The tasks may be one-off or long running. The long-running tasks can be gracefully terminated with shutdown handlers. Here is an example of a long running task which simply ticks every second. async def time_ticker ( shutdown_event : Event ) -> None : while not shutdown_event . is_set (): log . debug ( f 'time: { datetime . now () } ' ) try : await asyncio . wait_for ( shutdown_event . wait (), timeout = 1 ) except asyncio . TimeoutError : log . debug ( 'Timeout - normal behaviour when waiting with a timeout' ) except : log . exception ( 'Failure - we should not see this exception' ) log . debug ( 'The time ticker has stopped' ) async def time_ticker_startup_handler ( scope : Scope , info : Info , request : Message ) -> None : # Create an event that can be set when the background task should shutdown. shutdown_event = Event () info [ 'shutdown_event' ] = shutdown_event # Create the background task. info [ 'time_ticker_task' ] = asyncio . create_task ( time_ticker ( shutdown_event )) async def time_ticker_shutdown_handler ( scope : Scope , info : Info , request : Message ) -> None : # Set the shutdown event so the background task can stop gracefully. shutdown_event : Event = info [ 'shutdown_event' ] log . debug ( 'Stopping the time_ticker' ) shutdown_event . set () # Wait for the background task to finish. time_ticker_task : asyncio . Task = info [ 'time_ticker_task' ] log . debug ( 'Waiting for time_ticker' ) await time_ticker_task log . debug ( 'time_ticker shutdown' )","title":"Background Tasks"},{"location":"user-guide/background-tasks/#background-tasks","text":"It is a common requirement to run background tasks while the server is processing requests. For example incoming data might have to be processed before being used in subsequent responses. An important implementation details is that any code which uses the asyncio event loop (e.g. asyncio.Event(), asyncio.Queue(), etc.) must be done in the context of the ASGI server. Failure to do this will lead to errors complaining that the object is owned by a different event loop. This can be achieved by passing the application startup and shutdown handlers: async def my_startup_handler ( scope : Scope , info : Info , request : Message ) -> None : ... async def my_shutdown_handler ( scope : Scope , info : Info , request : Message ) -> None : ... # Create the application with startup and shutdown handlers. app = Application ( startup_handlers = [ my_startup_handler ], shutdown_handlers = [ my_shutdown_handler ] ) The tasks may be one-off or long running. The long-running tasks can be gracefully terminated with shutdown handlers. Here is an example of a long running task which simply ticks every second. async def time_ticker ( shutdown_event : Event ) -> None : while not shutdown_event . is_set (): log . debug ( f 'time: { datetime . now () } ' ) try : await asyncio . wait_for ( shutdown_event . wait (), timeout = 1 ) except asyncio . TimeoutError : log . debug ( 'Timeout - normal behaviour when waiting with a timeout' ) except : log . exception ( 'Failure - we should not see this exception' ) log . debug ( 'The time ticker has stopped' ) async def time_ticker_startup_handler ( scope : Scope , info : Info , request : Message ) -> None : # Create an event that can be set when the background task should shutdown. shutdown_event = Event () info [ 'shutdown_event' ] = shutdown_event # Create the background task. info [ 'time_ticker_task' ] = asyncio . create_task ( time_ticker ( shutdown_event )) async def time_ticker_shutdown_handler ( scope : Scope , info : Info , request : Message ) -> None : # Set the shutdown event so the background task can stop gracefully. shutdown_event : Event = info [ 'shutdown_event' ] log . debug ( 'Stopping the time_ticker' ) shutdown_event . set () # Wait for the background task to finish. time_ticker_task : asyncio . Task = info [ 'time_ticker_task' ] log . debug ( 'Waiting for time_ticker' ) await time_ticker_task log . debug ( 'time_ticker shutdown' )","title":"Background Tasks"},{"location":"user-guide/decorators/","text":"Decorators \u00b6 For small applications it can be more convenient to use decorators for add route and lifespan handlers. Here's a quick example: import uvicorn from bareasgi import Application , text_writer app = Application () @app . on_startup async def my_startup_handler ( scope , info , message ): print ( 'Starting up' ) @app . on_shutdown async def my_shutdown_handler ( scope , info , message ): print ( 'Shutting down' ) @app . on_http_request ({ 'GET' }, '/{rest:path}' ) async def http_request_callback ( scope , info , matches , content ): return 200 , [( b 'content-type' , b 'text/plain' )], text_writer ( 'This is not a test' ) uvicorn . run ( app , port = 9009 )","title":"Decorators"},{"location":"user-guide/decorators/#decorators","text":"For small applications it can be more convenient to use decorators for add route and lifespan handlers. Here's a quick example: import uvicorn from bareasgi import Application , text_writer app = Application () @app . on_startup async def my_startup_handler ( scope , info , message ): print ( 'Starting up' ) @app . on_shutdown async def my_shutdown_handler ( scope , info , message ): print ( 'Shutting down' ) @app . on_http_request ({ 'GET' }, '/{rest:path}' ) async def http_request_callback ( scope , info , matches , content ): return 200 , [( b 'content-type' , b 'text/plain' )], text_writer ( 'This is not a test' ) uvicorn . run ( app , port = 9009 )","title":"Decorators"},{"location":"user-guide/getting-started/","text":"Getting Started \u00b6 Here are some examples. More can be found in the github repository here . All the examples use the uvicorn server. The is further documentation on the types and utilities . Simple \u00b6 Here is a trivial example which registers a single http request callback at the endpoint /test and responds with the plain text This is not a test . 1 2 3 4 5 6 7 8 9 10 from bareasgi import Application , text_writer import uvicorn async def http_request_callback ( scope , info , matches , content ): return 200 , [( b 'content-type' , b 'text/plain' )], text_writer ( info [ 'message' ]) app = Application ( info = { 'message' : 'This is not a test' }) app . http_router . add ({ 'GET' }, '/test' , http_request_callback ) uvicorn . run ( app , port = 9009 ) The callback is defined on lines 4-5. The first argument scope is the dictionary passed straight through from the ASGI connection . The second argument info is client data passed into the server on line 7. This provides a mechanism for passing data around the application without the need for global variables. The third argument matches contains a dictionary of the variables which matched parts of the request url. As this route definition contained nothing to match this will be empty. The fourth and last argument content is an asynchronous iterator which provides the content of the request, and is not used here. The callback returns three things: the status code, a list of headers, and a writer. The headers are supplied as a list of name-value byte tuples. This is how the ASGI server expectes them, so no extra work need be done. The writer is an async iterator, meaning that the response supports streaming from the ground up. The application is created on line 7 with some client data containing the message to send. The route to the callback function is defined on line 8. As this in an HTTP route (rather than a websocket route) the http_router is used. The first argument to the router is the set of methods supported. These must be uppercase strings. The second argument as the path. This may contain matching variables, but in this case is a simple absolute path. The last argument is the HTTP response callback. Finally the web server is started on line 10. Rest Server \u00b6 The following example provides a simple REST service. A GET on the /info andpoint returns the contents of the info object, while a POST overwrites the INFO object with the contents of the body converted from json. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import json from bareasgi import Application , text_reader , text_writer import uvicorn async def get_info ( scope , info , matches , content ): text = json . dumps ( info ) return 200 , [( b 'content-type' , b 'application/json' )], text_writer ( text ) async def set_info ( scope , info , matches , content ): text = await text_reader ( content ) data = json . loads ( text ) info . update ( data ) return 204 app = Application ( info = { 'name' : 'Michael Caine' }) app . http_router . add ({ 'GET' }, '/info' , get_info ) app . http_router . add ({ 'POST' }, '/info' , set_info ) uvicorn . run ( app , port = 9009 ) This example demonstrates how the content can be retrieved from the request on line 10. Note how lightweight the response (on line 13) is, with simply the 204 (success not content) returned. Websocket Handler \u00b6 The following fragment shows a websocket callback. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 async def websocket_callback ( scope , info , matches , web_socket ): await web_socket . accept () try : while True : text = await web_socket . receive () if text is None : break await web_socket . send ( 'You said: ' + text ) except Exception as error : print ( error ) await web_socket . close () app = Application () app . ws_router . add ( '/test' , websocket_callback ) The web_socket object supplied on line 1 provides four methods: accept - to accept the web socket. This must be called first. receive - to read from the socket. When closed by the client None is returned. send - to write to the socket. close - to close the socket.","title":"Getting Started"},{"location":"user-guide/getting-started/#getting-started","text":"Here are some examples. More can be found in the github repository here . All the examples use the uvicorn server. The is further documentation on the types and utilities .","title":"Getting Started"},{"location":"user-guide/getting-started/#simple","text":"Here is a trivial example which registers a single http request callback at the endpoint /test and responds with the plain text This is not a test . 1 2 3 4 5 6 7 8 9 10 from bareasgi import Application , text_writer import uvicorn async def http_request_callback ( scope , info , matches , content ): return 200 , [( b 'content-type' , b 'text/plain' )], text_writer ( info [ 'message' ]) app = Application ( info = { 'message' : 'This is not a test' }) app . http_router . add ({ 'GET' }, '/test' , http_request_callback ) uvicorn . run ( app , port = 9009 ) The callback is defined on lines 4-5. The first argument scope is the dictionary passed straight through from the ASGI connection . The second argument info is client data passed into the server on line 7. This provides a mechanism for passing data around the application without the need for global variables. The third argument matches contains a dictionary of the variables which matched parts of the request url. As this route definition contained nothing to match this will be empty. The fourth and last argument content is an asynchronous iterator which provides the content of the request, and is not used here. The callback returns three things: the status code, a list of headers, and a writer. The headers are supplied as a list of name-value byte tuples. This is how the ASGI server expectes them, so no extra work need be done. The writer is an async iterator, meaning that the response supports streaming from the ground up. The application is created on line 7 with some client data containing the message to send. The route to the callback function is defined on line 8. As this in an HTTP route (rather than a websocket route) the http_router is used. The first argument to the router is the set of methods supported. These must be uppercase strings. The second argument as the path. This may contain matching variables, but in this case is a simple absolute path. The last argument is the HTTP response callback. Finally the web server is started on line 10.","title":"Simple"},{"location":"user-guide/getting-started/#rest-server","text":"The following example provides a simple REST service. A GET on the /info andpoint returns the contents of the info object, while a POST overwrites the INFO object with the contents of the body converted from json. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 import json from bareasgi import Application , text_reader , text_writer import uvicorn async def get_info ( scope , info , matches , content ): text = json . dumps ( info ) return 200 , [( b 'content-type' , b 'application/json' )], text_writer ( text ) async def set_info ( scope , info , matches , content ): text = await text_reader ( content ) data = json . loads ( text ) info . update ( data ) return 204 app = Application ( info = { 'name' : 'Michael Caine' }) app . http_router . add ({ 'GET' }, '/info' , get_info ) app . http_router . add ({ 'POST' }, '/info' , set_info ) uvicorn . run ( app , port = 9009 ) This example demonstrates how the content can be retrieved from the request on line 10. Note how lightweight the response (on line 13) is, with simply the 204 (success not content) returned.","title":"Rest Server"},{"location":"user-guide/getting-started/#websocket-handler","text":"The following fragment shows a websocket callback. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 async def websocket_callback ( scope , info , matches , web_socket ): await web_socket . accept () try : while True : text = await web_socket . receive () if text is None : break await web_socket . send ( 'You said: ' + text ) except Exception as error : print ( error ) await web_socket . close () app = Application () app . ws_router . add ( '/test' , websocket_callback ) The web_socket object supplied on line 1 provides four methods: accept - to accept the web socket. This must be called first. receive - to read from the socket. When closed by the client None is returned. send - to write to the socket. close - to close the socket.","title":"Websocket Handler"},{"location":"user-guide/h2/","text":"HTTP/2 \u00b6 Overview \u00b6 Upgrading to HTTP/2 is largely transparent. It requires: an ASGI server which supports is (e.g. Hypercorn ) TLS incryption HTTP Push \u00b6 There is a feature called HTTP/2 server push which allows the server to notify the client of urls required by the document being served before the client has received the document. This can be implemented in the following manner: async def test_page ( scope : Scope , info : Info , matches : RouteMatches , content : Content ) -> HttpResponse : html = \"\"\" <!DOCTYPE html> <html> <head> <meta charset=\"utf-8\"> <title>Example 1</title> <script src=\"/clickHandler.js\"></script> </head> <body> <h1>Example 1</h1> <button type=\"button\" onclick=\"handleClick('here')\"> Click me </button> <p id=\"here\" /> </body> </html> \"\"\" pushes = [ ( '/clickhandler.js' , [( b 'accept' , b 'text/javascript' )]) ] return 200 , [( b 'content-type' , b 'text/html' )], text_writer ( html ), pushes","title":"HTTP/2"},{"location":"user-guide/h2/#http2","text":"","title":"HTTP/2"},{"location":"user-guide/h2/#overview","text":"Upgrading to HTTP/2 is largely transparent. It requires: an ASGI server which supports is (e.g. Hypercorn ) TLS incryption","title":"Overview"},{"location":"user-guide/h2/#http-push","text":"There is a feature called HTTP/2 server push which allows the server to notify the client of urls required by the document being served before the client has received the document. This can be implemented in the following manner: async def test_page ( scope : Scope , info : Info , matches : RouteMatches , content : Content ) -> HttpResponse : html = \"\"\" <!DOCTYPE html> <html> <head> <meta charset=\"utf-8\"> <title>Example 1</title> <script src=\"/clickHandler.js\"></script> </head> <body> <h1>Example 1</h1> <button type=\"button\" onclick=\"handleClick('here')\"> Click me </button> <p id=\"here\" /> </body> </html> \"\"\" pushes = [ ( '/clickhandler.js' , [( b 'accept' , b 'text/javascript' )]) ] return 200 , [( b 'content-type' , b 'text/html' )], text_writer ( html ), pushes","title":"HTTP Push"},{"location":"user-guide/h3/","text":"HTTP/3 - QUIC \u00b6 Overview \u00b6 Upgrading to HTTP/3 is straightforward. It requires: an ASGI server which supports is (e.g. Hypercorn ) TLS incryption There is currently very little browser support for this. I was able to demonstrate that it was working with a nightly build of FireFox on Ubuntu 20.04 following these instructions. Example \u00b6 The following code launches a web server which supports: http on port 80 https on port 443 https using http/3 on port 4433 A browser that is capable of switching to http/3 will automatically upgrade the https connection. As this example uses \"standard\" ports you will need to run the server with sudo . Note the quic_bind line. \"\"\"Example server\"\"\" import asyncio import logging import os from bareasgi import Application , text_writer import bareutils.response_code as response_code from hypercorn.asyncio import serve from hypercorn.config import Config logging . basicConfig ( level = logging . DEBUG ) async def http_request_callback ( scope , info , matches , content ): text = \"\"\" <!doctype html> <html> <head> <title>Test</title> </head> <body> <p>This is not a test</p> </body> </html> \"\"\" headers = [ ( b 'content-type' , b 'text/html' ), ( b 'content-length' , str ( len ( text )) . encode ()) ] return response_code . OK , headers , text_writer ( text ) app = Application () app . http_router . add ({ 'GET' }, '/ {path} ' , http_request_callback ) config = Config () config . insecure_bind = [ '0.0.0.0:80' ] config . bind = [ '0.0.0.0:443' ] config . quic_bind = [ '0.0.0.0:4433' ] config . keyfile = os . path . expanduser ( '~/.keys/server.key' ) config . certfile = os . path . expanduser ( '~/.keys/server.crt' ) asyncio . run ( serve ( app , config ))","title":"HTTP/3 - QUIC"},{"location":"user-guide/h3/#http3-quic","text":"","title":"HTTP/3 - QUIC"},{"location":"user-guide/h3/#overview","text":"Upgrading to HTTP/3 is straightforward. It requires: an ASGI server which supports is (e.g. Hypercorn ) TLS incryption There is currently very little browser support for this. I was able to demonstrate that it was working with a nightly build of FireFox on Ubuntu 20.04 following these instructions.","title":"Overview"},{"location":"user-guide/h3/#example","text":"The following code launches a web server which supports: http on port 80 https on port 443 https using http/3 on port 4433 A browser that is capable of switching to http/3 will automatically upgrade the https connection. As this example uses \"standard\" ports you will need to run the server with sudo . Note the quic_bind line. \"\"\"Example server\"\"\" import asyncio import logging import os from bareasgi import Application , text_writer import bareutils.response_code as response_code from hypercorn.asyncio import serve from hypercorn.config import Config logging . basicConfig ( level = logging . DEBUG ) async def http_request_callback ( scope , info , matches , content ): text = \"\"\" <!doctype html> <html> <head> <title>Test</title> </head> <body> <p>This is not a test</p> </body> </html> \"\"\" headers = [ ( b 'content-type' , b 'text/html' ), ( b 'content-length' , str ( len ( text )) . encode ()) ] return response_code . OK , headers , text_writer ( text ) app = Application () app . http_router . add ({ 'GET' }, '/ {path} ' , http_request_callback ) config = Config () config . insecure_bind = [ '0.0.0.0:80' ] config . bind = [ '0.0.0.0:443' ] config . quic_bind = [ '0.0.0.0:4433' ] config . keyfile = os . path . expanduser ( '~/.keys/server.key' ) config . certfile = os . path . expanduser ( '~/.keys/server.crt' ) asyncio . run ( serve ( app , config ))","title":"Example"},{"location":"user-guide/installation/","text":"Installation \u00b6 The package can be installed with pip. pip install bareasgi This is a Python3.7 and later package. It has dependencies on: bareTypes bareUtils","title":"Installation"},{"location":"user-guide/installation/#installation","text":"The package can be installed with pip. pip install bareasgi This is a Python3.7 and later package. It has dependencies on: bareTypes bareUtils","title":"Installation"},{"location":"user-guide/io/","text":"Reading and Writing \u00b6 Reading and writing body content is performed with asynchronous iterators and generators. Note that the content is sent and received in bytes. Reading \u00b6 Here is a simple example of a reader that consumes all the body content and returns a string. async def text_reader ( content : Content ) -> str : text = '' async for b in content : text += b . decode () return text This mechanism means that no unnecessary work is done. For example if the content type was invalid it would be pointless to decode the body. Also if inconsistent data was found an error can be returned rather than reading all the data. Writing \u00b6 Here is a simple example of a reader that returns the body content as an async generator. async def text_writer ( text : str ) -> AsyncGenerator [ bytes , None ]: n = 512 while text : yield text [: n ] . encode () text = text [ n :] Breaking up the message in this manner allows the ASGI server more control over the data sent. If the receiving client decides to stop consuming the data, the remaining body need never be sent. Usage \u00b6 We might use these functions in a handler in the following manner: async def set_info ( scope , info , matches , content ): text = await text_reader ( content ) return 204 , None , text_writer ( f 'You said \" { text } \"' ) Notice how the text_reader is awaited. Chunking \u00b6 If content is sent without any headers an ASGI server will add the header transfer-encoding set to chunking . In this mode the server will send out each part of the body in length prefixed \"chunks\". If the content length is known and a content-length header is set, the ASGI server will not add the chunked transfer encoding, but you can still send the data in multiple parts. If the content length is incorrect, the ASGI server will not help you, and the receiver will be unable to properly receive the response.","title":"Reading and Writing"},{"location":"user-guide/io/#reading-and-writing","text":"Reading and writing body content is performed with asynchronous iterators and generators. Note that the content is sent and received in bytes.","title":"Reading and Writing"},{"location":"user-guide/io/#reading","text":"Here is a simple example of a reader that consumes all the body content and returns a string. async def text_reader ( content : Content ) -> str : text = '' async for b in content : text += b . decode () return text This mechanism means that no unnecessary work is done. For example if the content type was invalid it would be pointless to decode the body. Also if inconsistent data was found an error can be returned rather than reading all the data.","title":"Reading"},{"location":"user-guide/io/#writing","text":"Here is a simple example of a reader that returns the body content as an async generator. async def text_writer ( text : str ) -> AsyncGenerator [ bytes , None ]: n = 512 while text : yield text [: n ] . encode () text = text [ n :] Breaking up the message in this manner allows the ASGI server more control over the data sent. If the receiving client decides to stop consuming the data, the remaining body need never be sent.","title":"Writing"},{"location":"user-guide/io/#usage","text":"We might use these functions in a handler in the following manner: async def set_info ( scope , info , matches , content ): text = await text_reader ( content ) return 204 , None , text_writer ( f 'You said \" { text } \"' ) Notice how the text_reader is awaited.","title":"Usage"},{"location":"user-guide/io/#chunking","text":"If content is sent without any headers an ASGI server will add the header transfer-encoding set to chunking . In this mode the server will send out each part of the body in length prefixed \"chunks\". If the content length is known and a content-length header is set, the ASGI server will not add the chunked transfer encoding, but you can still send the data in multiple parts. If the content length is incorrect, the ASGI server will not help you, and the receiver will be unable to properly receive the response.","title":"Chunking"},{"location":"user-guide/middleware/","text":"Middleware \u00b6 Middleware is a chain of functions terminated by a callback. It can be used to add content to the request and response or to control the calling of subsequent handlers. A middleware callback is an async function with the following prototype. status , headers , content , pushes = await fn ( scope , info , matches , content , callback ) This is the same as an HTTP handler, with the addition of the callback which is either another middleware callback or an HTTP handler. Simple Example \u00b6 Here is a simple middleware example. import uvicorn from bareasgi import Application , text_writer async def first_middleware ( scope , info , matches , content , handler ): info [ 'message' ] = 'This is first the middleware. ' response = await handler ( scope , info , matches , content ) return response async def second_middleware ( scope , info , matches , content , handler ): info [ 'message' ] += 'This is the second middleware.' response = await handler ( scope , info , matches , content ) return response async def http_request_callback ( scope , info , matches , content ): return 200 , [( b 'content-type' , b 'text/plain' )], text_writer ( info [ 'message' ]) app = Application ( middlewares = [ first_middleware , second_middleware ]) app . http_router . add ({ 'GET' }, '/test' , http_request_callback ) uvicorn . run ( app , port = 9009 )","title":"Middleware"},{"location":"user-guide/middleware/#middleware","text":"Middleware is a chain of functions terminated by a callback. It can be used to add content to the request and response or to control the calling of subsequent handlers. A middleware callback is an async function with the following prototype. status , headers , content , pushes = await fn ( scope , info , matches , content , callback ) This is the same as an HTTP handler, with the addition of the callback which is either another middleware callback or an HTTP handler.","title":"Middleware"},{"location":"user-guide/middleware/#simple-example","text":"Here is a simple middleware example. import uvicorn from bareasgi import Application , text_writer async def first_middleware ( scope , info , matches , content , handler ): info [ 'message' ] = 'This is first the middleware. ' response = await handler ( scope , info , matches , content ) return response async def second_middleware ( scope , info , matches , content , handler ): info [ 'message' ] += 'This is the second middleware.' response = await handler ( scope , info , matches , content ) return response async def http_request_callback ( scope , info , matches , content ): return 200 , [( b 'content-type' , b 'text/plain' )], text_writer ( info [ 'message' ]) app = Application ( middlewares = [ first_middleware , second_middleware ]) app . http_router . add ({ 'GET' }, '/test' , http_request_callback ) uvicorn . run ( app , port = 9009 )","title":"Simple Example"},{"location":"user-guide/optional-packages/","text":"Optional Packages \u00b6 The following packages provide additional functionality: bareASGI-cors for CORS support. bareASGI-static for serving static files. bareASGI-jinja2 for templating with jinja2. bareASGI-graphql-next for GraphQL support. bareASGI-prometheus for Prometheus metrics middleware. bareClient a lightweight HTTP client.","title":"Optional Packages"},{"location":"user-guide/optional-packages/#optional-packages","text":"The following packages provide additional functionality: bareASGI-cors for CORS support. bareASGI-static for serving static files. bareASGI-jinja2 for templating with jinja2. bareASGI-graphql-next for GraphQL support. bareASGI-prometheus for Prometheus metrics middleware. bareClient a lightweight HTTP client.","title":"Optional Packages"},{"location":"user-guide/routing/","text":"Routing \u00b6 The routers are split into two: HTTP and WebSockets. A basic router is provided, but this can be replaced if required. HttpRouter \u00b6 The HTTP router has the following structure: class HttpRouter : @property def not_found_response ( self ): ... @not_found_response . setter def not_found_response ( self , value : HttpResponse ): ... def add ( self , methods : AbstractSet [ str ], path : str , callback : HttpRequestCallback ) -> None : ... def __call__ ( self , scope : Scope ) -> Tuple [ Optional [ HttpRequestCallback ], Optional [ RouteMatches ]]: ... WebSocketRouter \u00b6 The WebSocket router has the following structure: class WebSocketRouter ( metaclass = ABCMeta ): def add ( self , path : str , callback : WebSocketRequestCallback ) -> None : ... def __call__ ( self , scope : Scope ) -> Tuple [ Optional [ WebSocketRequestCallback ], Optional [ RouteMatches ]]: ... Paths \u00b6 Here are some example paths: literal_path = '/foo/bar' capture_trailing_paths = '/foo/ {path} ' variables_path = '/foo/ {name} /{id:int}/{created:datetime:%Y-%m- %d }' Matched path segments are passed in to the handlers as a dictionary of route matches.","title":"Routing"},{"location":"user-guide/routing/#routing","text":"The routers are split into two: HTTP and WebSockets. A basic router is provided, but this can be replaced if required.","title":"Routing"},{"location":"user-guide/routing/#httprouter","text":"The HTTP router has the following structure: class HttpRouter : @property def not_found_response ( self ): ... @not_found_response . setter def not_found_response ( self , value : HttpResponse ): ... def add ( self , methods : AbstractSet [ str ], path : str , callback : HttpRequestCallback ) -> None : ... def __call__ ( self , scope : Scope ) -> Tuple [ Optional [ HttpRequestCallback ], Optional [ RouteMatches ]]: ...","title":"HttpRouter"},{"location":"user-guide/routing/#websocketrouter","text":"The WebSocket router has the following structure: class WebSocketRouter ( metaclass = ABCMeta ): def add ( self , path : str , callback : WebSocketRequestCallback ) -> None : ... def __call__ ( self , scope : Scope ) -> Tuple [ Optional [ WebSocketRequestCallback ], Optional [ RouteMatches ]]: ...","title":"WebSocketRouter"},{"location":"user-guide/routing/#paths","text":"Here are some example paths: literal_path = '/foo/bar' capture_trailing_paths = '/foo/ {path} ' variables_path = '/foo/ {name} /{id:int}/{created:datetime:%Y-%m- %d }' Matched path segments are passed in to the handlers as a dictionary of route matches.","title":"Paths"},{"location":"user-guide/server-sent-events/","text":"Server Sent Events \u00b6 Server sent events can be implemented by providing an endpoint with an async generator. The following program provides an endpoint test_page for the html document which contains the JavaScript code to create the EventSource with a url served by the test_events function. This function returnes as the body an async generator which sends the time every second. When the event source is closed the task will be cancelled and the function exits. import asyncio from bareasgi import Application , text_writer from datetime import datetime import uvicorn async def test_page ( scope , info , matches , content ): html = \"\"\" <!DOCTYPE html> <html> <head> <meta charset=\"utf-8\"> <title>Example</title> </head> <body> <h1>Server Sent Events</h1> Time: <snap id=\"time\"></span> <script> var eventSource = new EventSource(\"http://localhost:9009/events\") eventSource.onmessage = function(event) { element = document.getElementById(\"time\") element.innerHTML = event.data } </script> </body> </html> \"\"\" return 200 , [( b 'content-type' , b 'text/html' )], text_writer ( html ) async def test_events ( scope , info , matches , content ): async def send_events (): is_cancelled = False while not is_cancelled : try : yield f 'data: { datetime . now () } \\n\\n\\n ' . encode ( 'utf-8' ) # Defeat buffering by giving the server a nudge. yield ': \\n\\n\\n ' . encode ( 'utf-8' ) await asyncio . sleep ( 1 ) except asyncio . CancelledError : is_cancelled = True headers = [ ( b 'cache-control' , b 'no-cache' ), ( b 'content-type' , b 'text/event-stream' ), ( b 'connection' , b 'keep-alive' ) ] return 200 , headers , send_events () app = Application () app . http_router . add ({ 'GET' }, '/' , index ) app . http_router . add ({ 'GET' }, '/test' , test_page ) app . http_router . add ({ 'GET' }, '/events' , test_events ) uvicorn . run ( app , host = 'localhost' , port = 9009 ) Note that we set the host to \"localhost\" to avoid CORS errors. Also, most ASGI servers (all the ones I've tried) buffer streaming data. The effect of this is that an event gets sent when the next event is yielded. We can defeat this by sending an SSE comment \":\\\\n\\\\n\\\\n\" . In the above example this can be seen by increasing the time tick from 1 second to 5 seconds, and observing the raw event stream in the Network tab of dev-tools in the browser. Without the \"nudge\" the timestamp is always out by the sleep interval.","title":"Server Sent Events"},{"location":"user-guide/server-sent-events/#server-sent-events","text":"Server sent events can be implemented by providing an endpoint with an async generator. The following program provides an endpoint test_page for the html document which contains the JavaScript code to create the EventSource with a url served by the test_events function. This function returnes as the body an async generator which sends the time every second. When the event source is closed the task will be cancelled and the function exits. import asyncio from bareasgi import Application , text_writer from datetime import datetime import uvicorn async def test_page ( scope , info , matches , content ): html = \"\"\" <!DOCTYPE html> <html> <head> <meta charset=\"utf-8\"> <title>Example</title> </head> <body> <h1>Server Sent Events</h1> Time: <snap id=\"time\"></span> <script> var eventSource = new EventSource(\"http://localhost:9009/events\") eventSource.onmessage = function(event) { element = document.getElementById(\"time\") element.innerHTML = event.data } </script> </body> </html> \"\"\" return 200 , [( b 'content-type' , b 'text/html' )], text_writer ( html ) async def test_events ( scope , info , matches , content ): async def send_events (): is_cancelled = False while not is_cancelled : try : yield f 'data: { datetime . now () } \\n\\n\\n ' . encode ( 'utf-8' ) # Defeat buffering by giving the server a nudge. yield ': \\n\\n\\n ' . encode ( 'utf-8' ) await asyncio . sleep ( 1 ) except asyncio . CancelledError : is_cancelled = True headers = [ ( b 'cache-control' , b 'no-cache' ), ( b 'content-type' , b 'text/event-stream' ), ( b 'connection' , b 'keep-alive' ) ] return 200 , headers , send_events () app = Application () app . http_router . add ({ 'GET' }, '/' , index ) app . http_router . add ({ 'GET' }, '/test' , test_page ) app . http_router . add ({ 'GET' }, '/events' , test_events ) uvicorn . run ( app , host = 'localhost' , port = 9009 ) Note that we set the host to \"localhost\" to avoid CORS errors. Also, most ASGI servers (all the ones I've tried) buffer streaming data. The effect of this is that an event gets sent when the next event is yielded. We can defeat this by sending an SSE comment \":\\\\n\\\\n\\\\n\" . In the above example this can be seen by increasing the time tick from 1 second to 5 seconds, and observing the raw event stream in the Network tab of dev-tools in the browser. Without the \"nudge\" the timestamp is always out by the sleep interval.","title":"Server Sent Events"},{"location":"user-guide/ssl/","text":"SSL/HTTPS \u00b6 Overview \u00b6 The following describes how to start some ASGI servers supporting SSL/HTTPS. You can find information on creating self signed certificates here . Uvicorn \u00b6 import uvicorn ... uvicorn . run ( app , host = '127.0.0.1' , port = 8008 , ssl_keyfile = 'foo.key' , ssl_certfile = 'foo.crt' ) Hypercorn \u00b6 import asyncio from hypercorn.asyncio import serve from hypercorn.config import Config ... web_config = Config () web_config . bind = [ '0.0.0.0:8008' ] web_config . keyfile = 'foo.key' web_config . certfile = 'foo.crt' asyncio . run ( serve ( app , web_config ))","title":"SSL/HTTPS"},{"location":"user-guide/ssl/#sslhttps","text":"","title":"SSL/HTTPS"},{"location":"user-guide/ssl/#overview","text":"The following describes how to start some ASGI servers supporting SSL/HTTPS. You can find information on creating self signed certificates here .","title":"Overview"},{"location":"user-guide/ssl/#uvicorn","text":"import uvicorn ... uvicorn . run ( app , host = '127.0.0.1' , port = 8008 , ssl_keyfile = 'foo.key' , ssl_certfile = 'foo.crt' )","title":"Uvicorn"},{"location":"user-guide/ssl/#hypercorn","text":"import asyncio from hypercorn.asyncio import serve from hypercorn.config import Config ... web_config = Config () web_config . bind = [ '0.0.0.0:8008' ] web_config . keyfile = 'foo.key' web_config . certfile = 'foo.crt' asyncio . run ( serve ( app , web_config ))","title":"Hypercorn"},{"location":"user-guide/usage/","text":"Usage \u00b6 The following trival example uses the uvicorn server. See here for more. import uvicorn import json from bareasgi import Application , text_reader , text_writer async def get_info ( scope , info , matches , content ): text = json . dumps ( info ) return 200 , [( b 'content-type' , b 'application/json' )], text_writer ( text ) async def set_info ( scope , info , matches , content ): text = await text_reader ( content ) data = json . loads ( text ) info . update ( data ) return 204 app = Application ( info = { 'name' : 'Michael Caine' }) app . http_router . add ({ 'GET' }, '/info' , get_info ) app . http_router . add ({ 'POST' }, '/info' , set_info ) uvicorn . run ( app , port = 9009 ) The above example demonstrates some of the key features of this implementation. All the handler arguments are simple Python objects (list, dict, tuple, etc). Arguments like scope are passed directly from the ASGI server without being processed into helper classes. All features (even JSON encoding) are the responsibility of the application, not the framework. Handlers are asynchronous. The text_writer function is a simple wrapper which turns text into an async byte stream.","title":"Usage"},{"location":"user-guide/usage/#usage","text":"The following trival example uses the uvicorn server. See here for more. import uvicorn import json from bareasgi import Application , text_reader , text_writer async def get_info ( scope , info , matches , content ): text = json . dumps ( info ) return 200 , [( b 'content-type' , b 'application/json' )], text_writer ( text ) async def set_info ( scope , info , matches , content ): text = await text_reader ( content ) data = json . loads ( text ) info . update ( data ) return 204 app = Application ( info = { 'name' : 'Michael Caine' }) app . http_router . add ({ 'GET' }, '/info' , get_info ) app . http_router . add ({ 'POST' }, '/info' , set_info ) uvicorn . run ( app , port = 9009 ) The above example demonstrates some of the key features of this implementation. All the handler arguments are simple Python objects (list, dict, tuple, etc). Arguments like scope are passed directly from the ASGI server without being processed into helper classes. All features (even JSON encoding) are the responsibility of the application, not the framework. Handlers are asynchronous. The text_writer function is a simple wrapper which turns text into an async byte stream.","title":"Usage"}]}